[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This is a course that is dear to my heart, and I‚Äôm excited to rediscover the the fascinating tools of this field with you.\nAs a graduate student, I actually worked in a completely different area for my dissertation. I focused on studying data from biological technologies (mass spectrometers and sequencing machines) and developing methods to analyze that data.\nIt was a happy and fortuitous occasion that I decided to take the course Causal Inference in Public Health during my 3rd year. I was immediately drawn in by the goals, tools, and application areas of the field‚Äîcausal inference researchers really seemed to be studying meaningful and impactful issues. While I had little time to explore more of causal inference for the remainder of my graduate studies, the fascination stuck with me.\nWhen I got to Macalester in 2018, the possibility of engaging more with causal inference opened up. I taught the first version of this course in Spring 2019 and have been steadily learning more over the years, improving this course along the way. I hope that you find ideas that intrigue you and applications that excite you.\nLet‚Äôs have a great semester!"
  },
  {
    "objectID": "syllabus.html#community-is-key",
    "href": "syllabus.html#community-is-key",
    "title": "Syllabus",
    "section": "Community is key",
    "text": "Community is key\nA sense of community and connectedness can provide a powerful environment for learning: Research shows that learning is maximized when students feel a sense of belonging in the educational environment (e.g., Booker, 2016). A negative climate may create barriers to learning, while a positive climate can energize students‚Äô learning (e.g., Pascarella & Terenzini, cited in How Learning Works, 2012).\nFor these reasons, I will be designing our in-class group activities to intentionally foster community and connectedness. You can help cultivate our classroom community by being thoughtful about the way you engage with others in class."
  },
  {
    "objectID": "syllabus.html#reflection-is-paramount",
    "href": "syllabus.html#reflection-is-paramount",
    "title": "Syllabus",
    "section": "Reflection is paramount",
    "text": "Reflection is paramount\nThe content you learn will be cool (unbiased opinion!), but it is a guarantee that you will venture into areas not covered in your formal education. We only have a short time together, and fields evolve constantly. There will be many times in your career where you will need to learn on your own. What you will need to rely on when you leave Macalester is what I want to ensure you cultivate now: a good learning process. And the cornerstone of a good learning process is reflection.\nReflection is not just fundamental to learning content‚Äìit‚Äôs fundamental to learning any sort of intellectual, emotional, or physical skill. For this reason, I will be prioritizing reflection in our activities and assignments throughout the semester."
  },
  {
    "objectID": "syllabus.html#mistakes-are-essential",
    "href": "syllabus.html#mistakes-are-essential",
    "title": "Syllabus",
    "section": "Mistakes are essential",
    "text": "Mistakes are essential\n\nAn expert is a person who has made all the mistakes which can be made in a narrow field.\n\nNiels Bohr, Nobel Prize-winning physicist\n\n\nPerhaps paradoxically, an important way to gain confidence in an area is to make a lot of mistakes. As you move through this course, make note of any time your understanding changed and the situation in which that change happened. Your understanding will grow richer for doing so."
  },
  {
    "objectID": "syllabus.html#communication-is-a-superpower",
    "href": "syllabus.html#communication-is-a-superpower",
    "title": "Syllabus",
    "section": "Communication is a superpower",
    "text": "Communication is a superpower\nEvery time I go to a conference talk on a technical topic, it is striking how quickly laptops or phones come out because of the inability to follow. Academics notoriously struggle to make ideas accessible to others.\nI want communication to be very different for you.\nEvery time you communicate ideas‚Äìwhether through writing, visuals, or oral presentation‚ÄìI want you to be a total boss. The end product of strong communication is a better experience for all those who have given you their attention. What‚Äôs more, the process of crafting effective communication is invaluable for deepening your own understanding:\n\n\n\nRead to collect the dots, write to connect them pic.twitter.com/YbgnKKFUNn\n\n‚Äî David Perell (@david_perell) July 5, 2021"
  },
  {
    "objectID": "syllabus.html#outside-of-class",
    "href": "syllabus.html#outside-of-class",
    "title": "Syllabus",
    "section": "Outside of class",
    "text": "Outside of class\nPre-class videos/readings: Most class periods will have a required video or reading to get acquainted with new concepts before seeing them again in class. Pre-class materials will focus more on conceptual ideas with less emphasis on code. My goal for these videos and readings is for you to familiarize yourself enough with the concepts so that we can go over both conceptual ideas and code in class.\n\n\n\n\n\n\nSuggestions\n\n\n\n\nAs you take notes on videos/readings, highlight or otherwise mark all the areas where you have questions. Gather up all of these questions in one place, and bring them to class with you.\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to attempt the upcoming assignment as soon as possible. Just by getting some rough ideas down quickly, you avoid the difficulty of starting from a blank slate.\nCome to instructor drop-in hours to chat about the course or anything else! üòÉ"
  },
  {
    "objectID": "syllabus.html#during-class",
    "href": "syllabus.html#during-class",
    "title": "Syllabus",
    "section": "During class",
    "text": "During class\nClass time will be a mixture of core idea days and flex days. On our schedule, any day that is not explicitly labeled as a flex day or project work day is a core idea day.\nOn core idea days, class time will be a mix of interactive lecture and stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise.\nOn flex days, there will be options to continue practicing the topics that we have covered recently or to explore some ideas in more detail.\n\n\n\n\n\n\nSuggestions\n\n\n\n\nThroughout class time, reference your set of questions from the pre-class material. Have you made progress on addressing those questions? Who or what helped with improving your understanding, and how? Make notes of what concepts are still unclear so that you can review later."
  },
  {
    "objectID": "syllabus.html#my-philosophy",
    "href": "syllabus.html#my-philosophy",
    "title": "Syllabus",
    "section": "My philosophy",
    "text": "My philosophy\nGrading is thorny issue for many educators because of its known negative effects on learning and motivation. Nonetheless, it is ever-present in the US education system and at Macalester. Because I am required to submit grades for this course, it‚Äôs worth me taking a minute to share my philosophy about grading with you.\nWhat excites me about being a teacher is your learning.\nLearning flourishes in an environment where you find meaning and value in what we‚Äôre exploring, feel supported when engaging with challenges, receive useful feedback, and regularly reflect on your learning.\nIf I didn‚Äôt have to give grades, I wouldn‚Äôt. But because I am required to, it is important to me to create a course structure and grading system that allow learning to flourish:\n\nFinding meaning and value: I am striving to achieve this by:\n\nCreating space for authentic connection between you, your peers, and myself\nBuilding flex days into our schedule so that you have time to focus on what you want to get out of the course\nEncouraging you to explore a topic that intrigues you for our course project\n\nSupport in engaging with challenges: The assignments and activities that we will use to learn are meant to be challenging, and it would be unreasonable for me to expect that you have perfect understanding on the first try. For this reason, the opportunity to revise without penalty on assignments is something I believe in strongly. Solid learning does not happen under excessive stress, and I think that a lot of that stress comes from the general culture of perfection in academia.\nReceiving useful feedback and reflecting regularly: My aim with feedback is to always provide guidance towards improvement, no matter where you are in your progress. However, good feedback alone is useless‚Äîlearners need to engage deeply with feedback in order to benefit the most from it. For this reason, my stance on feedback is the following: I only want to give feedback on work that you want to read feedback on. This informs the approach that we‚Äôll take for assignments in this course."
  },
  {
    "objectID": "syllabus.html#assignments-and-assessments",
    "href": "syllabus.html#assignments-and-assessments",
    "title": "Syllabus",
    "section": "Assignments and assessments",
    "text": "Assignments and assessments\nThere are no in-class examinations (like quizzes or exams) in this course. A portfolio and a course project are the two sources of submitted work that will receive feedback.\n\nPortfolio\nPurpose: Over the course of the semester, you‚Äôll build up a portfolio in which you organize course ideas that are most important to you in a way that is most beneficial to your future self. My hope is that you can easily use this portfolio in the future in case you want a reference that is tailored to you.\nOverview:\n\nStarting the 3rd week of the semester, an assignment will be due every Friday in which you add to this portfolio.\nThese assignments will ask you to reorganize the information from course topics in a way that is more optimal for you to navigate. In completing these assignments, you have the freedom to draw from class activities, but you will need to add explanations, transitions between ideas, and connections that we won‚Äôt necessarily do together in class activities.\nMost of the time, you‚Äôll submit these assignments as Quarto files (.qmd) because you‚Äôll be required to include both code and writing. I‚Äôll add comments directly to your .qmd file and re-upload them as feedback on Moodle.\n\nDetails for all assignments can be found on the Assignments page.\n\n\nProject\nPurpose: Complete a project that you would be proud to talk about in depth during a job interview or present during MSCS Capstone Days in the spring.\nOverview:\n\nTwo main options for the project are available: (1) a data analysis using causal tools and (2) creating a tutorial on a topic not covered in class. If you feel strongly about pursuing a different type of project, we can meet to discuss.\nThrough weekly milestones at the end of the semester, you will make steady progress on your projects and iterate on feedback.\n\nFull details about the project can be found on the Project page."
  },
  {
    "objectID": "syllabus.html#course-grading-system",
    "href": "syllabus.html#course-grading-system",
    "title": "Syllabus",
    "section": "Course grading system",
    "text": "Course grading system\n\n\n\n\n\n\nBefore Assignment 1\n\n\n\n\n\nBefore I decide on a course grading system, I would like your input. Everyone has different sources of motivation and thrives in different types of environments, and I would like to learn more about each of your motivations before making decisions on a system that could have notable impacts on your experience in the course.\nAssignment 1 will be a short piece of writing that helps me learn about you in this regard. We will use insights from your writing to inform a discussion on the grading system in the first weeks of class.\n\n\n\nConsistent themes that I saw throughout your responses to Assignment 1 included the following:\n\nThe idea of an A as a default starting point was intriguing to try given the existence of other strong motivators. Many of you mentioned that the desire to learn more about the field and to create a project you would be proud to share with others are powerful sources of motivation. Given these motivators, a system where an A is the default can relieve stress and encourage a focus on ideas rather than a preoccupation with performance on assessments.\nIt would feel better if a grade of an A as a default were linked with expectations. You offered ideas of earning an A contingent on coming to class most of the time and completing assignments rather than on ‚Äúperfecting‚Äù assignments according to some point scale or rubric.\nQualitative feedback, reflection, and revision are essential parts of the learning process and should be part of the grading system. Some of you expressed the desire to require revisions and reflection in response to thoughtful qualitative feedback.\nIt is important to get everyone‚Äôs input and hear what others have to say. Many of you mentioned being open to whatever grading system works best for everyone and that a fair way to decide could be to vote or have an in-class discussion.\n\n\nBased on these themes, I am proposing the following Contract for an A this semester:\n\n\n\n\n\n\nContract for an A\n\n\n\nTo earn an A for the semester, we agree to the following:\n\nActively co-create our course learning community alongside peers and the instructor.\n\nOur strongest learning will occur when we feel like we‚Äôre doing work alongside others who want the same things.\nBeing an active co-creator of our learning community will entail coming prepared to class as much as we can: engaging with pre-class materials thoughtfully by noting down interesting ideas and questions that you hope to have answered and sharing them with peers in class.\nWe will support the learning of our peers by thoughtfully engaging with class activities.\nEveryone will advocate for their own learning by communicating regularly with the instructor about what is working well and can be improved.\n\nComplete all assignments to the best of your ability and consistently respond to feedback.\n\nResponding to feedback involves revising work and/or writing a message to the instructor to continue the conversation from the previous round of feedback.\nQualitative feedback will always communicate areas for growth. Sometimes that growth can be approached with a revision of prior work, and sometimes it can be approached by articulating plans for what to work on in the future.\n\nReflect on your progress at the midway point and at the end of the semester.\n\nI will provide prompts at both points to help you look back on past work and look forward to continued growth.\n\nCreate and present a high quality project that you would be proud to share on capstone days or with future employers.\n\nThrough regular milestones and qualitative feedback on each milestone, we‚Äôll work towards creating work that you are proud of."
  },
  {
    "objectID": "syllabus.html#late-work",
    "href": "syllabus.html#late-work",
    "title": "Syllabus",
    "section": "Late work",
    "text": "Late work\nHomework assignments will generally be due weekly on Fridays at 5pm. If you anticipate needing more time to complete an assignment, please email me ahead of time to discuss. My main constraint is the desire to give you feedback before the next assignment is due, and I‚Äôll be working on feedback on the Monday-Thursday after an assignment is due."
  },
  {
    "objectID": "syllabus.html#academic-integrity",
    "href": "syllabus.html#academic-integrity",
    "title": "Syllabus",
    "section": "Academic integrity",
    "text": "Academic integrity\nAcademic integrity is the cornerstone of our learning community. Students are expected to be familiar with the college‚Äôs standards on academic integrity.\nI encourage you to work with your classmates to discuss material and ideas for assignments, but in order for you to receive individualized feedback on your own learning, you must submit your own work. This involves writing your own code and putting explanations into your own words. Always cite any sources you use, including AI (see section below)."
  },
  {
    "objectID": "syllabus.html#artificial-intelligence-ai-use",
    "href": "syllabus.html#artificial-intelligence-ai-use",
    "title": "Syllabus",
    "section": "Artificial intelligence (AI) use",
    "text": "Artificial intelligence (AI) use\nAI can both interfere with and enhance our capacity to learn. We must be mindful of when it might hinder us and when it might provide us with new understanding and/or assistance. What is most important to me about our AI usage in this course is the following:\n\nAI usage must always be cited with the prompt and full output.\n\nWhy do I care about this? I want to see and give feedback on your thinking.\nI will not use AI frequently out of personal preference, but when I do, I will always share the prompt and output.\n\nAI output can be a part of your responses on assignments, but it always needs to be accompanied by double-checking, commentary, and interpretation from you.\n\nWhy do I care about this? Again, I want to see and give feedback on your thinking. But also quite importantly, AI does not always generate complete and/or accurate output. Because of its training data, it will almost certainly hallucinate or give inaccurate information when asked about more modern advances in the field.\n\n\nPlease be aware of the following general limitations of AI:\n\nAI does not always generate accurate output. If it gives you a number, fact, or code, assume it is wrong unless you either know the answer or can check in with another source. AI works best for topics you already understand to a sufficient extent.\nIf you provide minimum effort prompts, you will get low quality results. You will need to refine your prompts in order to get good outcomes. This will take work.\nBe thoughtful about when this tool is useful. Don‚Äôt use it if it isn‚Äôt appropriate for the case or circumstance.\nThe environmental impact of AI should not be ignored. The building and usage of AI tools consume a lot of energy (see here and here). For this reason, let‚Äôs be thoughtful about when we use AI and think about other sustainability behaviors that we can incorporate into our lives to offset this usage.\n\nIf you have any questions about your use of AI tools, please contact me to discuss them."
  },
  {
    "objectID": "slides/01-introductions.html#welcome-to-causal-inference",
    "href": "slides/01-introductions.html#welcome-to-causal-inference",
    "title": "Welcome to Causal Inference!",
    "section": "Welcome to Causal Inference!",
    "text": "Welcome to Causal Inference!\nTo follow along:\n\nOpen Moodle\nUnder Course Resources, click link for our course website\nUnder Activities (top menu), click ‚ÄúIntroductions and foundational ideas‚Äù\n\nQuote of the day:\n\nNew goals don‚Äôt deliver new results. New lifestyles do. And a lifestyle is a process, not an outcome. For this reason, all of your energy should go into building better habits, not chasing better results.\n\nJames Clear"
  },
  {
    "objectID": "slides/01-introductions.html#building-community",
    "href": "slides/01-introductions.html#building-community",
    "title": "Welcome to Causal Inference!",
    "section": "Building community",
    "text": "Building community\nBefore we start talking about causal inference, we will take time to get to know each other.\nTake 5 minutes to have a conversation with the people at your table:\n\nIntroduce yourselves however you see fit.\nWhat‚Äôs something that‚Äôs on your mind this fall?"
  },
  {
    "objectID": "slides/01-introductions.html#my-causal-journey",
    "href": "slides/01-introductions.html#my-causal-journey",
    "title": "Welcome to Causal Inference!",
    "section": "My causal journey",
    "text": "My causal journey\nSpring 2016 - Causal Inference in Medicine and Public Health with Dr.¬†Elizabeth Stuart"
  },
  {
    "objectID": "slides/01-introductions.html#my-causal-journey-1",
    "href": "slides/01-introductions.html#my-causal-journey-1",
    "title": "Welcome to Causal Inference!",
    "section": "My causal journey",
    "text": "My causal journey\nOn the first day, she presented the kinds of questions that we‚Äôd be trying to answer:\n\nDoes the Head Start program improve educational and health outcomes for children?\nDoes participation in a perinatal depression prevention program improve postpartum mental health?\nBy how much do high-level NICU‚Äôs reduce infant mortality?\nDoes a ‚Äúhealthy marriage‚Äù intervention improve relationship quality?\n\nMy eyes were big and locked in‚Äìin a way that I hadn‚Äôt felt in a long time.\n(This was actually only my second ever applied statistics course. Every other course I had taken was largely theoretical!)"
  },
  {
    "objectID": "slides/01-introductions.html#should-we",
    "href": "slides/01-introductions.html#should-we",
    "title": "Welcome to Causal Inference!",
    "section": "Should we?",
    "text": "Should we?\n\nDoes the Head Start program improve educational and health outcomes for children?\nDoes participation in a perinatal depression prevention program improve postpartum mental health?\nBy how much do high-level NICU‚Äôs reduce infant mortality?\nDoes a ‚Äúhealthy marriage‚Äù intervention improve relationship quality?"
  },
  {
    "objectID": "slides/01-introductions.html#should-we-1",
    "href": "slides/01-introductions.html#should-we-1",
    "title": "Welcome to Causal Inference!",
    "section": "Should we?",
    "text": "Should we?\n\nDoes the Head Start program improve educational and health outcomes for children? Should we continue to fund and run Head Start programs the way they‚Äôre currently being implemented?\n\nFor all children? What types of children benefit more or less than others?\n\nDoes participation in a perinatal depression prevention program improve postpartum mental health? Should we increase access to these depression prevention programs for all pregnant individuals?\n\nFor all pregnant individuals? What characteristics of individuals might cause them to benefit more than others?"
  },
  {
    "objectID": "slides/01-introductions.html#some-inspiration",
    "href": "slides/01-introductions.html#some-inspiration",
    "title": "Welcome to Causal Inference!",
    "section": "Some inspiration",
    "text": "Some inspiration\n\nThese tools and ideas are the kinds of things that, if you use them right, can turn you from a consumer of knowledge into a producer. You can find the answer to questions nobody else has the answer to. You can figure out how the world really works on your own. I think that‚Äôs pretty darn cool!\nThe Effect - Introduction"
  },
  {
    "objectID": "slides/01-introductions.html#plan-for-remainder-of-today",
    "href": "slides/01-introductions.html#plan-for-remainder-of-today",
    "title": "Welcome to Causal Inference!",
    "section": "Plan for remainder of today",
    "text": "Plan for remainder of today\n\nLet‚Äôs take some time to clarify our intuitions and natural inclinations surrounding the idea of causation.\nThis will help us develop a core framework for our course."
  },
  {
    "objectID": "slides/01-introductions.html#reflection-known-causes",
    "href": "slides/01-introductions.html#reflection-known-causes",
    "title": "Welcome to Causal Inference!",
    "section": "Reflection: Known causes",
    "text": "Reflection: Known causes\nThink about some causal relationships that you are sure about‚Äîwhere you can say ‚ÄúI know that ___ causes ___.‚Äù\nHow do you know?"
  },
  {
    "objectID": "slides/01-introductions.html#bradford-hill-criteria",
    "href": "slides/01-introductions.html#bradford-hill-criteria",
    "title": "Welcome to Causal Inference!",
    "section": "Bradford-Hill criteria",
    "text": "Bradford-Hill criteria\nIn 1965, the English statistician Sir Austin Bradford Hill proposed 9 criteria for evaluating the evidence for causal relationships:\n\nStrength: Big associations might be more likely to be causal.\nConsistency: Replicability of the finding across samples and contexts lends support for a causal relationship.\nSpecificity: A causal relationship is more likely if there is a very specific population at a specific site and disease with no other likely explanation.\nTemporality: Exposure/treatment happens first, then the outcome.\nBiological gradient: A dose‚Äìresponse relationship. Increasing the amount of exposure should generally lead to a more pronounced effect.\nPlausibility: Being able to explain why. A reported relationship is more plausible if there are reasonable mechanism(s) for the relationship. (Knowledge of the mechanism is limited by current knowledge.)\nCoherence: The coherence between different sources of evidence (e.g., epidemiological and laboratory findings).\nExperiment: Evidence from controlled experiments can be compelling.\nAnalogy: The observed association is just like (analogous to) some other association.\n\nLucy D‚ÄôAgostino McGowan at Vanderbilt came up with a great mapping between these criteria and xkcd cartoons‚Äìsee here for her full talk. I‚Äôll show some of my favorites."
  },
  {
    "objectID": "slides/01-introductions.html#strength",
    "href": "slides/01-introductions.html#strength",
    "title": "Welcome to Causal Inference!",
    "section": "Strength",
    "text": "Strength\n\nSource"
  },
  {
    "objectID": "slides/01-introductions.html#consistency",
    "href": "slides/01-introductions.html#consistency",
    "title": "Welcome to Causal Inference!",
    "section": "Consistency",
    "text": "Consistency\n\nSource"
  },
  {
    "objectID": "slides/01-introductions.html#temporality",
    "href": "slides/01-introductions.html#temporality",
    "title": "Welcome to Causal Inference!",
    "section": "Temporality",
    "text": "Temporality\n\nSource"
  },
  {
    "objectID": "slides/01-introductions.html#what-if",
    "href": "slides/01-introductions.html#what-if",
    "title": "Welcome to Causal Inference!",
    "section": "What if?",
    "text": "What if?\nMaybe we are sure about some causes because we really do feel like we know what would have happened if things had somehow been different."
  },
  {
    "objectID": "slides/01-introductions.html#potential-outcomes",
    "href": "slides/01-introductions.html#potential-outcomes",
    "title": "Welcome to Causal Inference!",
    "section": "Potential outcomes",
    "text": "Potential outcomes\nThe outcomes that would (potentially) result under different scenarios of an exposure or treatment.\n\n\n\\(A\\): Treatment or exposure variable (‚ÄúA‚Äù for action)\n\nOften binary but doesn‚Äôt have to be: \\(A = 1\\) for treated/exposed. \\(A = 0\\) for controls/untreated/unexposed\n\n\\(Y\\): Observed outcome\n\\(Y^a\\): Potential outcomes\n\n\\(Y^{a=1}\\): Potential outcome under treatment. What the outcome would be if the unit received treatment.\n\\(Y^{a=0}\\): Potential outcome under control. What the outcome would be if the unit did not receive treatment.\nWe can only observe one potential outcome.\nWhy? Potential outcomes are the answer to ‚ÄúWhat if?‚Äù\nThey are specific to a particular unit and point in time. (e.g., Me on 9/1/2024 at 11:11AM, Minnesota in August 2024)"
  },
  {
    "objectID": "slides/01-introductions.html#potential-outcomes-in-movies",
    "href": "slides/01-introductions.html#potential-outcomes-in-movies",
    "title": "Welcome to Causal Inference!",
    "section": "Potential outcomes in movies",
    "text": "Potential outcomes in movies\nIn It‚Äôs a Wonderful Life, George Bailey gets help from his guardian angel Clarence to see how the lives of those close to him would have turned out if he had never been born."
  },
  {
    "objectID": "slides/01-introductions.html#potential-outcomes-in-movies-1",
    "href": "slides/01-introductions.html#potential-outcomes-in-movies-1",
    "title": "Welcome to Causal Inference!",
    "section": "Potential outcomes in movies",
    "text": "Potential outcomes in movies\nIn Everything Everywhere All at Once, Evelyn Wang is able get a glimpse of the lives of the people around her under different ‚Äúincarnations‚Äù of herself."
  },
  {
    "objectID": "slides/01-introductions.html#potential-outcomes-example-1",
    "href": "slides/01-introductions.html#potential-outcomes-example-1",
    "title": "Welcome to Causal Inference!",
    "section": "Potential outcomes: Example 1",
    "text": "Potential outcomes: Example 1\nI‚Äôm about to drive to Minneapolis.\n\n\\(A = 1\\): Take the highway to Minneapolis\n\\(A = 0\\): Take city roads to Minneapolis\n\\(Y\\): Observed commute time (minutes) on Sept 1, 2024 at 5:12PM\n\\(Y^{a=1}\\): Commute time on Sept 1, 2024 at 5:12PM if taking the highway\n\\(Y^{a=0}\\): Commute time on Sept 1, 2024 at 5:12PM if taking city roads\n\nI decide to take city roads.\n\n\\(Y = 25\\)\n\\(Y^{a=0} = 25\\)\nSuppose my friend simultaneously heads out and takes the highway and it takes 42 minutes. We have not observed what would have happened if I took the highway, but we are pretty confident that \\(Y^{a=1} = 42\\).\nThe causal effect of taking the highway vs.¬†city roads on Sept 1, 2024 at 5:12PM is an excess commute time of 42-25 = 17 minutes."
  },
  {
    "objectID": "slides/01-introductions.html#potential-outcomes-example-2",
    "href": "slides/01-introductions.html#potential-outcomes-example-2",
    "title": "Welcome to Causal Inference!",
    "section": "Potential outcomes: Example 2",
    "text": "Potential outcomes: Example 2\nI wake up in the morning with a headache.\n\n\\(A = 1\\): Take aspirin for my headache\n\\(A = 0\\): Do nothing for my headache\n\\(Y\\): Headache outcome (headache / no headache) on Sept 1, 2024 at 8:34AM\n\\(Y^{a=1}\\): Headache outcome on on Sept 1, 2024 at 8:34AM if taking aspirin\n\\(Y^{a=0}\\): Headache outcome on on Sept 1, 2024 at 8:34AM if doing nothing\n\nI take an aspirin.\n\n\\(Y = \\text{no headache}\\)\n\\(Y^{a=1} = \\text{no headache}\\)\n\\(Y^{a=0} = ?\\)\n\nI don‚Äôt know if my headache would have gone away on its own.\nMaybe I remember enough about previous headaches to guess that it probably would not have.\nBut the guess of \\(Y^{a=0} = \\text{headache}\\) is a guess. Truly \\(Y^{a=0}\\) is unknowable."
  },
  {
    "objectID": "slides/01-introductions.html#potential-outcomes-example-3",
    "href": "slides/01-introductions.html#potential-outcomes-example-3",
    "title": "Welcome to Causal Inference!",
    "section": "Potential outcomes: Example 3",
    "text": "Potential outcomes: Example 3\nColleges are deciding whether to adopt a test-optional admissions policy.\n\n\\(A = 1\\): College adopts a test-optional admissions policy\n\\(A = 0\\): College does not adopt a test-optional admissions policy\n\\(Y\\): Number of applications for regular decision enrollment for Fall 2024\n\\(Y^{a=1}\\): # applications under a test-optional admissions policy\n\\(Y^{a=0}\\): # applications without a test-optional admissions policy\n\nMacalester adopts a test-optional admissions policy in 2020.\n\n\\(Y = 8915\\)\n\\(Y^{a=1} = 8915\\)\n\\(Y^{a=0} = ???\\)\n\nVery hard to know how many applicants Mac would have received without the policy.\nBut if were to collect a lot of data over time on many colleges, we might be able to learn about average potential outcomes."
  },
  {
    "objectID": "slides/01-introductions.html#potential-outcomes-and-average-causal-effects",
    "href": "slides/01-introductions.html#potential-outcomes-and-average-causal-effects",
    "title": "Welcome to Causal Inference!",
    "section": "Potential outcomes and average causal effects",
    "text": "Potential outcomes and average causal effects\n\nThe previous examples focused on potential outcomes (POs) for a given unit (an individual, a college).\nContrasting these POs for a single unit is very interesting but very hard to do with confidence.\nEasier and also useful to contrast POs on average for many (a sample of) units‚Äìthis is the idea of an average causal effect (ACE)."
  },
  {
    "objectID": "slides/01-introductions.html#potential-outcomes-across-many-units",
    "href": "slides/01-introductions.html#potential-outcomes-across-many-units",
    "title": "Welcome to Causal Inference!",
    "section": "Potential outcomes across many units",
    "text": "Potential outcomes across many units\n\n\n\n\\(A\\)\n\\(Y^{a=1}\\)\n\\(Y^{a=0}\\)\n\n\n\n\n1\n0\n?\n\n\n1\n0\n?\n\n\n1\n1\n?\n\n\n0\n?\n1\n\n\n0\n?\n1\n\n\n0\n?\n0\n\n\n\nThe fact that there is a ? in every row is known as the fundamental problem of causal inference.\nDespite this fundamental problem, we have ways of making good guesses about the missing potential outcomes on average."
  },
  {
    "objectID": "slides/01-introductions.html#average-causal-effects",
    "href": "slides/01-introductions.html#average-causal-effects",
    "title": "Welcome to Causal Inference!",
    "section": "Average causal effects",
    "text": "Average causal effects\n\n\\(E[Y]\\) means expected value of \\(Y\\)\n\nThis is formally a probability concept, but it has intuition that we can work with.\nIt‚Äôs a weighted average of the possible values of \\(Y\\) weighted by how common those values are.\n\n\n\n\n\n\\(A\\)\n\\(Y^{a=1}\\)\n\\(Y^{a=0}\\)\n\n\n\n\n1\n0\n?\n\n\n1\n0\n?\n\n\n1\n1\n?\n\n\n0\n?\n1\n\n\n0\n?\n1\n\n\n0\n?\n0\n\n\n\n\nOne average causal effect is a mean difference:\n\n\\(E[Y^{a=1} - Y^{a=0}] = E[Y^{a=1}] - E[Y^{a=0}]\\)\n\nThe expected value of a binary (0/1) variable is the probability that it equals one.\nIn this context, mean difference is a probability difference. How much does aspirin change the probability of a headache persisting?\nIn the test-optional admissions policy context, mean difference is a difference in the average number of applications. How much does a test optional policy change applicant volume?"
  },
  {
    "objectID": "slides/01-introductions.html#recap-and-reflection",
    "href": "slides/01-introductions.html#recap-and-reflection",
    "title": "Welcome to Causal Inference!",
    "section": "Recap and reflection",
    "text": "Recap and reflection\nLet‚Äôs take a few minutes to reflect on the ideas of potential outcomes and how we‚Äôre defining causal effects. Are these satisfying ways for you to think about causation?"
  },
  {
    "objectID": "slides/01-introductions.html#what-level-will-the-course-be-at",
    "href": "slides/01-introductions.html#what-level-will-the-course-be-at",
    "title": "Welcome to Causal Inference!",
    "section": "What level will the course be at?",
    "text": "What level will the course be at?\n\nWaived Probability prereq this semester\n\nThis subject is routinely taught in master‚Äôs level programs in public health without probability.\nIf you have taken Probability, it can deepen your understanding from a technical/theoretical standpoint.\nTotally possible to use our tools very well to be a producer of knowledge without knowing probability."
  },
  {
    "objectID": "slides/01-introductions.html#what-level-will-the-course-be-at-1",
    "href": "slides/01-introductions.html#what-level-will-the-course-be-at-1",
    "title": "Welcome to Causal Inference!",
    "section": "What level will the course be at?",
    "text": "What level will the course be at?\n\nIn this book I‚Äôll cover what a causal research question even is, and how we can do the hard work of answering that causal research question once we have it.\nI‚Äôll do that while scaling far back on equations and proofs. There‚Äôs absolutely a technical element to causal inference, and we‚Äôll get to some of that in this book. But when you talk to people who actually do causal research, they think of this stuff intuitively first, not mathematically. They talk about assumptions about the real world and whether they‚Äôre reasonable, and what the story is behind the data. After they‚Äôve got that settled, then they worry about equations and statistical properties. Designing good research and proving (or even understanding) statistical theorems are separate tasks. I think they should be introduced in that order.\nThe Effect - Introduction"
  },
  {
    "objectID": "slides/01-introductions.html#flex-days",
    "href": "slides/01-introductions.html#flex-days",
    "title": "Welcome to Causal Inference!",
    "section": "Flex Days",
    "text": "Flex Days\nI want you to get what you want out of this course.\nGiven the diversity of our class, a one-size-fits-all approach to what we cover and do in class is not going to work.\nRoughly every 1.5 weeks, one class day will be a Flex Day.\n\nFlex Days are you for to focus on what you need to make the course a success‚Äîeveryone will be doing something different. (I encourage grouping up to form exploration communities.)\nI‚Äôll provide materials for you to explore that day.\nI‚Äôll do my best to provide a wide variety of materials to explore, but I‚Äôll need you to tell me if what you want to explore is missing.\nGeneral themes for exploration:\n\nApplications + more examples of the week‚Äôs content (like more practice exercises with different data, reading applied research papers)\nDigging into theory / technical details\nSimulation exercises in R"
  },
  {
    "objectID": "slides/01-introductions.html#grading-system",
    "href": "slides/01-introductions.html#grading-system",
    "title": "Welcome to Causal Inference!",
    "section": "Grading system",
    "text": "Grading system\n\nYou‚Äôll notice from our syllabus that I have not spelled out a grading system.\nAssignment 1 is a short piece of writing to help me get to know you and move towards deciding on what to do about grading in this course. Due next Wednesday, 9/11.\nRegardless of what we decide for grading, the two main sources of work that receives feedback are (1) the portfolio and (2) the course project.\n\nPortfolio is built up over weekly assignments (starting week 3). My hope is that it serves as a good reference for you in the future."
  },
  {
    "objectID": "slides/01-introductions.html#for-next-time",
    "href": "slides/01-introductions.html#for-next-time",
    "title": "Welcome to Causal Inference!",
    "section": "For next time",
    "text": "For next time\n\nCheck the Schedule for readings from The Effect. (Chapters 1, 2, and 5)\n\nReadings from The Effect always have video alternatives from the textbook author.\n\nUpdate your R and RStudio installations as described here."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "Overview: Perform a causal analysis on a dataset of your choice.\nCollaboration: Groups of up to 3. Individual work is fine.\nResources for finding data:\nIt‚Äôs fine with me if you use a dataset associated with an existing project (like an honors project) or a projec for another class (as long as it‚Äôs ok with the other instructor).\n\nGoogle Dataset Search\nHarvard Dataverse\nInter-university Consortium for Political and Social Research (ICPSR)\nIPUMS\nMacalester‚Äôs librarians can also be a great resource for finding data. Schedule an appointment with them here.\n\n\n\n\n\nOverview: Dig deeper into existing course topics or learn a new topic. Examples could include:\n\nMethods for transportability (generalizability) of effects\nInterference\nSpecialized considerations for particular study designs\nMachine learning in causal inference\nIndividual causal effect estimation\n\nCollaboration: Groups of up to 3. Individual work is fine.\n\n\n\n\nIf none of these options piques your interest, I‚Äôm happy to discuss alternatives with you. Some ideas:\n\nDesign a Shiny app to illustrate causal concepts to students\nWrite (part of) an R package for making it easier to work with causal graphs\nCritique of applied research\n\nThis is a good option for those who would like to do a data analysis but cannot find adequate data to pursue their question.\nFind and read papers that study a question of interest to you. Critique these papers from a causal inference lens. This will involve constructing your own causal graph to guide a critique of the authors‚Äô data collection and analysis methods.\nDiscuss what remains uncertain in this line of research, and propose an analysis plan for a new causal study to rectify the limitations of prior research."
  },
  {
    "objectID": "project.html#option-1-data-analysis",
    "href": "project.html#option-1-data-analysis",
    "title": "Project",
    "section": "",
    "text": "Overview: Perform a causal analysis on a dataset of your choice.\nCollaboration: Groups of up to 3. Individual work is fine.\nResources for finding data:\nIt‚Äôs fine with me if you use a dataset associated with an existing project (like an honors project) or a projec for another class (as long as it‚Äôs ok with the other instructor).\n\nGoogle Dataset Search\nHarvard Dataverse\nInter-university Consortium for Political and Social Research (ICPSR)\nIPUMS\nMacalester‚Äôs librarians can also be a great resource for finding data. Schedule an appointment with them here."
  },
  {
    "objectID": "project.html#option-2-learn-an-advanced-topic",
    "href": "project.html#option-2-learn-an-advanced-topic",
    "title": "Project",
    "section": "",
    "text": "Overview: Dig deeper into existing course topics or learn a new topic. Examples could include:\n\nMethods for transportability (generalizability) of effects\nInterference\nSpecialized considerations for particular study designs\nMachine learning in causal inference\nIndividual causal effect estimation\n\nCollaboration: Groups of up to 3. Individual work is fine."
  },
  {
    "objectID": "project.html#option-3-other",
    "href": "project.html#option-3-other",
    "title": "Project",
    "section": "",
    "text": "If none of these options piques your interest, I‚Äôm happy to discuss alternatives with you. Some ideas:\n\nDesign a Shiny app to illustrate causal concepts to students\nWrite (part of) an R package for making it easier to work with causal graphs\nCritique of applied research\n\nThis is a good option for those who would like to do a data analysis but cannot find adequate data to pursue their question.\nFind and read papers that study a question of interest to you. Critique these papers from a causal inference lens. This will involve constructing your own causal graph to guide a critique of the authors‚Äô data collection and analysis methods.\nDiscuss what remains uncertain in this line of research, and propose an analysis plan for a new causal study to rectify the limitations of prior research."
  },
  {
    "objectID": "project.html#milestone-1",
    "href": "project.html#milestone-1",
    "title": "Project",
    "section": "Milestone 1",
    "text": "Milestone 1\nDue date: Friday, November 8 at 5PM\nAs part of this milestone, you will pick a project option, pick a specific topic, and form a group (if not working alone).\nYou will submit a short write-up that varies by project option. (No page length requirements‚Äîjust convey the information that you need to.)\n\nData analysis option: You will write a draft of the Introduction, Data, and Methods sections of your paper.\n\nIntroduction: Give background for your topic, including relevant theory, domain knowledge, and prior research. Incorporate findings from at least 3 journal articles.\nData: Describe the data that you have and how it was collected. Include any limitations or cautions that are important to keep in mind about the data. Think about the who, what, when, where, why, and how behind your data to inform your discussion in this section.\nMethods: Write a detailed plan for the analyses that you will conduct. This part can be written in bullet points.\n\nAdvanced topic option: Your final paper will be structured as a tutorial, and for this milestone, you‚Äôll make progress towards writing this tutorial.\n\nIntroduce the big idea behind this topic. Make connections between your topic and the topics we covered in class so that others can have a better sense of how this topic fits into the field of causal inference.\nExplain 1 idea that you learned from your research so far. Include a citation to at least 1 journal article.\nWrite a plan for your remaining research. Describe the ideas are you planning to learn in the remaining time. Describe a simulation study that you will perform to explore some of the theory behind your topic."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "These assignments will build up your Portfolio. Recall from the syllabus that the goal of the Portfolio is create a reference that is tailored to the way that you think about and understand ideas.\nI hope that you feel proud of your Portfolio by the end of the semester. If you want to publish it, the Quarto files (.qmd) that you submit for your assignments can become the basis for a website that looks a lot like this course website or websites in the Quarto gallery. I‚Äôm happy to help you get this set up if you‚Äôre interested.\n\n\nAssignment 1\nDue Wednesday, 9/11 at 5pm on Moodle\nThis first assignment is a short writing piece for me to get to know you. There are no length requirements‚Äîjust use as many words as needed to convey what you want, and feel free to respond to my questions in any order.\nFormat: Please submit a link to a Google Doc (preferred) or a Word document. (No PDFs because comments end up being too scrunched in PDFs.) If submitting a Google Doc, make sure that I am added with either Editing or Commenting privileges.\nPrompt:\nI recently read a moving essay called An Education of His Own by writer Latham Turner. I invite you to read this essay as you think about what you might want from this course experience. If you feel so moved, I‚Äôd love to hear what parts of the essay resonated with you.\nWhat would make this course of a success for you? What are you hoping to learn and accomplish? I know that there are a variety of reasons for taking the course, and I want to better understand how those reasons inform what you are hoping for.\nReflect on other courses you‚Äôve taken and other learning environments in which you‚Äôve participated. What grading/motivation/incentive structures, classroom dynamics, and personal habits/practices were helpful for your learning? What hindered your learning?\nFor the next questions, I want to be honest with you about where I am coming from. I mentioned in the syllabus that if I didn‚Äôt have to give grades, I wouldn‚Äôt. The act of grading (putting points and A/B/C-like marks on work) is quite draining for me because I feel immense pressure to be fair, be ‚Äúaccurate‚Äù (even though there is no way that something like a grade could accurately measure something as complex as learning), and keep your motivation levels high. I also feel that grading creates a charged power dynamic between the instructor and the student that I don‚Äôt like. I became a teacher because I love being a guide and a coach for students in ideas I find fascinating‚Äînot because I wanted to bestow judgment.\nIf my aversion to grades seems like an aversion to high expectations for your learning, it‚Äôs not. It‚Äôs an aversion to what I see as a very problematic system when something more simple and more meaningful encourages learning so well: qualitative feedback. Note that grading is very different from qualitative feedback, which, simply put, is a collection of thoughtful comments on your work. I truly enjoy giving feedback when it is not tied to a grade. There‚Äôs so much rich information in qualitative feedback that grades, by virtue of being a single letter or number, can‚Äôt capture.\nWith that background from me, I have a few questions for you: How would you feel about a system in which everyone gets an A so that we can ignore grades completely and focus on qualitative feedback? How would you feel about a system in which everyone was graded differently? How do you think we should approach the process of deciding to how to handle grades in this course?\nI know that the background I gave suggests what I would prefer for what we do with grades. I know that this may affect your comfort in being honest, but I truly do want to know your honest thoughts.\nThanks for taking the time to reflect and share with me. I‚Äôm looking forward to reading what you write.\n\n\n\nAssignment 2\nDue Friday, 9/27 at 5pm on Moodle\nImagine that you are preparing your capstone talk on your project from this course. The start of that presentation should probably include a section that introduces orients them to what the course is even about: What is causal inference? What are causal graphs, and what role do they play in causal inference?\nTask: Create slides for this presentation section. Add presenter notes beneath each slide to indicate what you would say. If you wish, you can record a video of you giving this presentation segment.\nAudience: Aim for this presentation segment to be accessible to students who have taken STAT 155 but no upper-level courses.\nFormat:\n\nFor submitting slides, Google Slides is preferred‚Äîmake sure that I am added with either Editing or Commenting privileges. If using another program for slides, submit both the slides and presenter notes beneath in PDF format.\nIf submitting a video, upload the video or share a link where I can access it."
  },
  {
    "objectID": "07-rct.html",
    "href": "07-rct.html",
    "title": "Randomized experiments",
    "section": "",
    "text": "Goals\n\nExplain why randomized controlled trials (RCTs) are the gold standard for causal inference\n\nMake connections to the structure of a causal diagram for an RCT\n\nExplain the importance of blinding study subjects and investigators\nEvaluate the pros and cons of different randomization strategies\nExplain the role of precision variables in the analysis of RCT results\nConduct balance checks to assess the quality of a particular randomization\n\n\nYou can download a template file for this activity here.\n\nlibrary(dagitty)\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(broom)\nlibrary(cobalt)\n\n cobalt (Version 4.5.5, Build Date: 2024-04-02)\n\n\n\n\nTerminology\n\nAlso called randomized controlled trials (RCTs)\nIn industry, called A/B testing\n\n\n\n\nWhat is a randomized experiment?\n\nA study design in which units are randomly assigned to treatment conditions, which is a form of intervention.\n\nNote: I‚Äôm intentionally using the term ‚Äútreatment condition‚Äù rather than ‚Äútreatment group‚Äù here.\nTreatment groups are the groups with different values of the treatment variable: 1 = receives treatment, 0 = control group that doesn‚Äôt receive treatment.\nA treatment condition is a particular treatment group in a particular environment. A hugely important part of the environment ends up being time. We‚Äôll explore this more shortly.\n\nNonexperimental studies are generally called observational studies because investigators only get to observe the experiences of study units without intervening.\n\n\n\n\nWhy are RCTs regarded as the gold standard for causal inference?\nThe causal graph below shows a hypothesized data-generating process relevant to a treatment \\(A\\) and outcome \\(Y\\). This is what we would have to work with in an observational study.\n\nobs_dag &lt;- dagitty('\ndag {\nA [exposure,pos=\"0.295,1.003\"]\nC1 [pos=\"0.123,0.736\"]\nC2 [pos=\"0.031,0.371\"]\nC3 [pos=\"0.262,0.477\"]\nC4 [pos=\"0.438,0.506\"]\nC5 [pos=\"0.376,0.147\"]\nC6 [pos=\"0.628,0.332\"]\nC7 [pos=\"0.920,0.382\"]\nC8 [pos=\"0.920,0.561\"]\nM [pos=\"0.604,0.954\"]\nY [outcome,pos=\"0.916,1.016\"]\nA -&gt; M\nA -&gt; Y\nC1 -&gt; A\nC1 -&gt; C3\nC1 -&gt; Y\nC2 -&gt; C1\nC2 -&gt; C3\nC2 -&gt; C4\nC2 -&gt; C5\nC2 -&gt; C6\nC3 -&gt; A\nC3 -&gt; C4\nC3 -&gt; C5\nC3 -&gt; C6\nC4 -&gt; A\nC4 -&gt; C5\nC4 -&gt; C7\nC4 -&gt; C8\nC4 -&gt; M\nC6 -&gt; A\nC6 -&gt; C8\nC7 -&gt; C8\nM -&gt; C8\nM -&gt; Y\n}\n')\nplot(obs_dag)\n\n\n\n\n\n\n\n\nThe data-generating process for a randomized experiment looks different because all direct causes of treatment cease to be direct causes. The only thing that determines treatment condition is a random number generator (RNG):\n\nrct_dag &lt;- dagitty('\ndag {\nA [exposure,pos=\"0.295,1.003\"]\nC1 [pos=\"0.123,0.736\"]\nC2 [pos=\"0.031,0.371\"]\nC3 [pos=\"0.262,0.477\"]\nC4 [pos=\"0.438,0.506\"]\nC5 [pos=\"0.376,0.147\"]\nC6 [pos=\"0.628,0.332\"]\nC7 [pos=\"0.920,0.382\"]\nC8 [pos=\"0.920,0.561\"]\nM [pos=\"0.604,0.954\"]\nRNG [pos=\"0.066,0.890\"]\nY [outcome,pos=\"0.916,1.016\"]\nA -&gt; M\nA -&gt; Y\nC1 -&gt; C3\nC1 -&gt; Y\nC2 -&gt; C1\nC2 -&gt; C3\nC2 -&gt; C4\nC2 -&gt; C5\nC2 -&gt; C6\nC3 -&gt; C4\nC3 -&gt; C5\nC3 -&gt; C6\nC4 -&gt; C5\nC4 -&gt; C7\nC4 -&gt; C8\nC4 -&gt; M\nC6 -&gt; C8\nC7 -&gt; C8\nM -&gt; C8\nM -&gt; Y\nRNG -&gt; A\n}\n')\nplot(rct_dag)\n\n\n\n\n\n\n\n\nQuestion: In terms of causal and noncausal paths, what is the key difference between these two causal graphs?\n\n\n\nBackdoor vs.¬†other noncausal paths\n\nKey idea: randomization cuts off (removes) ALL backdoor paths (noncausal paths that start by pointing to treatment).\n\nThis includes backdoor paths that could only be blocked with unmeasured variables!\n\nBut randomization doesn‚Äôt do anything to other noncausal paths leading from treatment.\n\n\n\n\n\nNoncompliance and blinding\nSuppose that a randomized experiment is evaluating the effect of a new medication versus an existing medication for cholesterol levels.\nQuestion: For the following 3 considerations, discuss with your group: what would happen to the generic RCT causal diagram if each of the following were a concern? Draw an updated diagram for each consideration. (Handle each consideration separately.)\n\nWhat if subjects don‚Äôt comply with the treatment they were randomly assigned?\nWhat if subjects know what treatment they were assigned?\nWhat if study investigators know what treatment group a subject was assigned to?\n\n\nrct_dag &lt;- dagitty('\ndag {\nbb=\"0,0,1,1\"\n\"A: treatment\" [exposure,pos=\"0.250,0.500\"]\n\"Y: outcome\" [outcome,pos=\"0.750,0.500\"]\nConfounders [pos=\"0.500,0.250\"]\nRNG [pos=\"0.073,0.377\"]\n\"A: treatment\" -&gt; \"Y: outcome\"\nConfounders -&gt; \"Y: outcome\"\nRNG -&gt; \"A: treatment\"\n}\n')\nplot(rct_dag)\n\n\n\n\n\n\n\n\n\n\n\nRandomization schemes: exploration\nWe mentioned earlier that a randomized experiment randomizes units to treatment conditions. How exactly this randomization is done can vary and can have important consequences.\nExercise: Take a look at this figure from the paper The ‚Äúcompletely randomised‚Äù and the ‚Äúrandomised block‚Äù are the only experimental designs suitable for widespread use in pre-clinical research.\n\nFrom the figure and the text in the figure legend, what seems to be the difference between these randomization methods?\nWhat does the figure do well to communicate differences between randomization methods? What could be improved?\nAfter reading the ‚ÄúDetails about randomization methods‚Äù section below, how would you recommend updating the figure to be more clear?\n\nDetails about randomization methods\n\nComplete randomization:\n\nA method in which assignment to treatment group as well as treatment order is randomized. The number of units assigned to each treatment group can be controlled.\nExample: If we want to have 100 treated units and 200 control units, we create a random sequence of 100 1‚Äôs and 200 0‚Äôs to perform this randomization.\n\nBlock randomization (related to stratified randomization)\n\nForm ‚Äúblocks‚Äù (groups) of units that are identical (or as close as possible)\nWithin each block randomize each unit to a treatment group and randomize the order of the units\nExample: We want to ensure that age (young, old) and prior experience (low, high) are balanced between the treatment and control groups. These two variables define 4 blocks or strata:\n\nAge = young, prior exp = low: 6 units\nRandomization: 0 0 1 1 0 1\nAge = young, prior exp = high: 8 units\nRandomization: 1 1 0 1 0 0 0 1\nAge = old, prior exp = low: 4 units\nRandomization: 1 0 0 1\nAge = old, prior exp = high: 6 units\nRandomization: 1 1 0 0 1 0\n\n\n\n\n\n\nChecking the balance of a randomization\nAfter obtaining a random assignment, it is important to check that the treatment groups are balanced in terms of variables that affect the outcome.\nThe cobalt package provides a convenient way to do this with the bal.tab() function:\n\nset.seed(451)\nn &lt;- 1000\nsim_data &lt;- tibble(\n    A = sample(c(rep(0, n/2), rep(1, n/2))),\n    C1 = rnorm(n, mean = 2, sd = 1),\n    C2 = rnorm(n, mean = 2, sd = 1),\n    mean_Y = A + C1 + C2,\n    noise_Y = rnorm(n, mean = 0, sd = 5),\n    Y = mean_Y + noise_Y\n)\n\n# The bal.tab() function from the cobalt package\n# automatically computes balance statistics\n# Continuous variables: standardized mean differences (difference in means divided by a pooled estimate of the std dev from both groups)\n# Binary variables: raw differences in proportion\nbal.tab(A ~ C1 + C2, data = sim_data, s.d.denom = \"pooled\")\n\nBalance Measures\n      Type Diff.Un\nC1 Contin.  0.0341\nC2 Contin.  0.0464\n\nSample sizes\n    Control Treated\nAll     500     500\n\n\n\n\n\nPrecision variables\nQuestion: Based on the simulation code below, what causal graph represents the data-generating process? What can you infer is the causal effect of A on Y?\n\nset.seed(451)\nn &lt;- 1000\nsim_data &lt;- tibble(\n    A = sample(c(rep(0, n/2), rep(1, n/2))),\n    C1 = rnorm(n, mean = 2, sd = 1),\n    C2 = rnorm(n, mean = 2, sd = 1),\n    C3 = rnorm(n, mean = 2, sd = 1),\n    C4 = rnorm(n, mean = 2, sd = 1),\n    mean_Y = 5*A + C1 + C2 + C3 + C4,\n    noise_Y = rnorm(n, mean = 0, sd = 5),\n    Y = mean_Y + noise_Y\n)\n\nThe simulation below uses the same RCT data-generating process as above. It conducts 1000 of these RCTs and fits two different models. Read through this code to understand what is being done. Then work on the exercises beneath the code chunk.\n\n# Helper function to organize linear regression model output\ntidy_model_output &lt;- function(mod, type) {\n    tidy(mod, conf.int = TRUE, conf.level = 0.95) %&gt;% \n        mutate(model_type = type) %&gt;% \n        filter(term==\"A\")\n}\n\nset.seed(451)\nsim_results &lt;- replicate(1000, {\n    n &lt;- 1000\n    sim_data &lt;- tibble(\n        A = sample(c(rep(0, n/2), rep(1, n/2))),\n        C1 = rnorm(n, mean = 2, sd = 1),\n        C2 = rnorm(n, mean = 2, sd = 1),\n        C3 = rnorm(n, mean = 2, sd = 1),\n        C4 = rnorm(n, mean = 2, sd = 1),\n        mean_Y = 5*A + C1 + C2 + C3 + C4,\n        noise_Y = rnorm(n, mean = 0, sd = 5),\n        Y = mean_Y + noise_Y\n    )\n    \n    # Fit a linear regression model with only A as a predictor\n    mod_unadj &lt;- lm(Y ~ A, data = sim_data)\n    # Fit a model with C1 to C4 as covariates\n    mod_adj &lt;- lm(Y ~ A + C1 + C2 + C3 + C4, data = sim_data)\n    \n    # Store results for the coefficient on A in a data frame\n    bind_rows(\n        tidy_model_output(mod_unadj, type = \"unadjusted\"),\n        tidy_model_output(mod_adj, type = \"adjusted\")\n    )\n}, simplify = FALSE)\n\nsim_results &lt;- bind_rows(sim_results)\n\n# Peek at the simulation results data frame\nhead(sim_results)\n\n# A tibble: 6 √ó 8\n  term  estimate std.error statistic  p.value conf.low conf.high model_type\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     \n1 A         5.09     0.335      15.2 3.77e-47     4.43      5.75 unadjusted\n2 A         5.13     0.315      16.3 4.69e-53     4.51      5.75 adjusted  \n3 A         5.13     0.336      15.2 2.73e-47     4.47      5.79 unadjusted\n4 A         5.26     0.307      17.1 6.20e-58     4.65      5.86 adjusted  \n5 A         5.28     0.342      15.4 2.98e-48     4.61      5.95 unadjusted\n6 A         5.12     0.312      16.4 1.09e-53     4.51      5.74 adjusted  \n\n\nExercise: Create visualizations that compare the estimated causal effect and the uncertainty in that estimate between model types. What do you learn from these plots?\n(It may help to use the ggplot2 cheatsheet: HTML version, PDF version.)\nExercise: In the simulation above, we explored adjusting for the direct causes of outcome Y. Suppose that we weren‚Äôt able to measure the direct causes (C1 to C4), but that we only had measures of proxies. (For example, ‚Äúwillingness to volunteer‚Äù might be a direct cause of an outcome, but we can only measure number of volunteer hours in the past month.) How might we adapt the simulation setup above to investigate how adjusting for proxies changes the comparison between the unadjusted and adjusted models?",
    "crumbs": [
      "Randomized experiments"
    ]
  },
  {
    "objectID": "05-causal-graphs-identification.html",
    "href": "05-causal-graphs-identification.html",
    "title": "Identifying causal effects with causal graphs",
    "section": "",
    "text": "Explain how d-separation and causal/noncausal paths relate to identification of causal effects.\nApply d-separation to block noncausal paths in causal DAGs with and without unobserved variables.\nApply strategies to deal with identification problems caused by unobserved variables.\nDifferentiate confounding and selection bias in terms of graph structure and how they arise in applied studies.",
    "crumbs": [
      "Identifying causal effects with causal graphs"
    ]
  },
  {
    "objectID": "05-causal-graphs-identification.html#exercise-1",
    "href": "05-causal-graphs-identification.html#exercise-1",
    "title": "Identifying causal effects with causal graphs",
    "section": "Exercise 1",
    "text": "Exercise 1\nFor each of the causal graphs below, identify the set of variables needed to block noncausal paths (if possible) between treatment \\(A\\) and outcome \\(Y\\). Any \\(U\\) variables displayed in the graphs are unobserved/unmeasured.",
    "crumbs": [
      "Identifying causal effects with causal graphs"
    ]
  },
  {
    "objectID": "05-causal-graphs-identification.html#exercise-2",
    "href": "05-causal-graphs-identification.html#exercise-2",
    "title": "Identifying causal effects with causal graphs",
    "section": "Exercise 2",
    "text": "Exercise 2\nHistorically, people have tried to create definitions for confounders by listing criteria that purely rely on associations. For example:\n\nA confounder must:\n1. Be associated with treatment and outcome\n2. Not be caused by treatment\n\nUsing the causal graph below, explain why this is not a good definition for a confounder.",
    "crumbs": [
      "Identifying causal effects with causal graphs"
    ]
  },
  {
    "objectID": "05-causal-graphs-identification.html#exercise-3",
    "href": "05-causal-graphs-identification.html#exercise-3",
    "title": "Identifying causal effects with causal graphs",
    "section": "Exercise 3",
    "text": "Exercise 3\nFirst, think through the relationships depicted in the causal graphs below and whether they make sense. These are intended to reflect a range of scenarios for why people drop out of studies.\nThen for each of the graphs, identify the set of variables that would block noncausal paths between the treatment \\(A\\) and outcome \\(Y\\). (\\(U\\) and \\(W\\) are unmeasured.) Check your answers to one of the graphs using DAGitty.",
    "crumbs": [
      "Identifying causal effects with causal graphs"
    ]
  },
  {
    "objectID": "05-causal-graphs-identification.html#exercise-4",
    "href": "05-causal-graphs-identification.html#exercise-4",
    "title": "Identifying causal effects with causal graphs",
    "section": "Exercise 4",
    "text": "Exercise 4\nIn this exercise, we‚Äôll consider how causal graphs can inform study design. (Inspired by a 1970s study on the relationship between estrogen use and endometrial cancer.)\nResearchers have noticed a consistent association between use of a certain drug and disease. Research groups debated two hypotheses:\n\nThe drug does cause disease.\nThe drug doesn‚Äôt actually cause disease but leads to a side effect, leading to more frequent doctor visits, leading to increased diagnosis of existing disease.\n\nThe following study plan was proposed: restrict the study only to those with side effects and compare disease rates in drug-users and non-users. In this way, all participants have the same chance of being diagnosed.\nThe following causal graphs correspond to the two hypotheses:\n\n\n\n(The graphs don‚Äôt show confounders of the drug-true disease relationship for compactness. We can assume that these have already been adjusted for.)\n\nStudy design 1\nConsider the study proposal above: restrict analysis to those with side effects.\n\nBefore looking at the causal graphs: does the rationale for this study design make sense? Why did researchers want to only look at patients with side effects?\nUnder this study design, the researchers were expecting that if Hypothesis 1 were correct (the drug does cause disease), they would find an association between drug use and diagnosed disease. They expected that if Hypothesis 2 were correct (the drug does NOT cause disease), they would find NO association between drug use and diagnosed disease.\n\nAre these expectations correct? Explain in light of the causal graphs.\n\nBased on your answer above, is this an effective study design for the research questions of interest? That is, can this study proposal distinguish between the two hypotheses?\n\n\n\nStudy design 2\nConsider another study proposal: ensure that everyone is screened for disease frequently, and we don‚Äôt restrict our analysis to only those with side effects.\n\nWhat arrow can be removed as a result of this study design? (It might help to draw an updated version of DAGs 1 and 2 with this arrow removed.)\nUnder this study design, the researchers had the same expectations: if Hypothesis 1 were correct, they would find an association between drug use and diagnosed disease. If Hypothesis 2 were correct, they would find NO association between drug use and diagnosed disease.\n\nAre these expectations correct? Explain in light of the causal graphs.\n\nBased on your answer above, is this an effective study design for the research questions of interest? That is, can this study proposal distinguish between the two hypotheses?",
    "crumbs": [
      "Identifying causal effects with causal graphs"
    ]
  },
  {
    "objectID": "03-causal-graphs-intro.html",
    "href": "03-causal-graphs-intro.html",
    "title": "Causal graph fundamentals",
    "section": "",
    "text": "Practice graphically showing our beliefs about data-generating processes using causal graphs\nExpand our worldview by exploring interesting questions in domains that we don‚Äôt normally think about\nBuild a trusting intellectual community by being curious about each other‚Äôs interests, giving kind and actionable feedback, and receiving feedback with curiosity and gratitude",
    "crumbs": [
      "Causal graph fundamentals"
    ]
  },
  {
    "objectID": "03-causal-graphs-intro.html#identification",
    "href": "03-causal-graphs-intro.html#identification",
    "title": "Causal graph fundamentals",
    "section": "Identification",
    "text": "Identification\n\nIdentification is the process of isolating only desired variation (variation corresponding purely to our causal effect of interest) and ruling out alternate explanations\nRuling out alternate explanations requires understanding the data-generating process",
    "crumbs": [
      "Causal graph fundamentals"
    ]
  },
  {
    "objectID": "03-causal-graphs-intro.html#causal-diagrams",
    "href": "03-causal-graphs-intro.html#causal-diagrams",
    "title": "Causal graph fundamentals",
    "section": "Causal diagrams",
    "text": "Causal diagrams\nA causal diagram (causal graph) is a visual representation of a data-generating process and are directed acyclic graphs (DAGs).\nNodes represent variables and edges represent direct causal relationships between variables.\nWe will be conceptualizing causality in the following way: A is a cause of Y if changes in the value of A change the probability distribution of Y.\n\nNote 1: In practice, people in the field say that the presence of an arrow indicates that A might cause Y.\nNote 2: If changes in the value of A change the value of Y, we often equate this with a change in mean, but it doesn‚Äôt have to. (e.g., the mean might not change, but the variance could)\n\n\n\nCode\ndat &lt;- bind_rows(\n    tibble(\n        x = seq(-4, 4, by = 0.1),\n        y = dnorm(x, 0, 1),\n        type = \"Control PO\",\n        context = \"Change in means\"\n    ),\n    tibble(\n        x = seq(-4, 4, by = 0.1),\n        y = dnorm(x, 1, 1),\n        type = \"Treated PO\",\n        context = \"Change in means\"\n    ),\n    tibble(\n        x = seq(-4, 4, by = 0.1),\n        y = dnorm(x, 0, 1),\n        type = \"Control PO\",\n        context = \"Change in variance\"\n    ),\n    tibble(\n        x = seq(-4, 4, by = 0.1),\n        y = dnorm(x, 0, 2),\n        type = \"Treated PO\",\n        context = \"Change in variance\"\n    )\n)\n\nggplot(dat, aes(x = x, y = y, color = type)) +\n    geom_line() +\n    facet_grid(~ context) +\n    theme_classic() +\n    scale_color_manual(values = c(\"steelblue\", \"darkorange\"))",
    "crumbs": [
      "Causal graph fundamentals"
    ]
  },
  {
    "objectID": "03-causal-graphs-intro.html#warm-up-1",
    "href": "03-causal-graphs-intro.html#warm-up-1",
    "title": "Causal graph fundamentals",
    "section": "Warm-up 1",
    "text": "Warm-up 1\nWe‚Äôre interested in the question ‚ÄúDoes reading Harry Potter as a child make you read more as an adult?‚Äù A causal diagram is shown below.\n\n\nCode\n# Requires the dagitty package to be loaded\ndag1 &lt;- dagitty(\"dag {\n    bb=\\\"0,0,1,1\\\"\n    AgeWhenPotterReleased [pos=\\\"0.200,0.200\\\"]\n    LikesReading [latent,pos=\\\"0.500,0.350\\\"]\n    ReadOtherRowlingBooks [pos=\\\"0.500,0.650\\\"]\n    ReadPotterAsKid [exposure,pos=\\\"0.200,0.500\\\"]\n    ReadingAsAdult [outcome,pos=\\\"0.800,0.500\\\"]\n    AgeWhenPotterReleased -&gt; ReadPotterAsKid\n    LikesReading -&gt; ReadPotterAsKid\n    LikesReading -&gt; ReadingAsAdult\n    ReadOtherRowlingBooks -&gt; ReadingAsAdult\n    ReadPotterAsKid -&gt; ReadOtherRowlingBooks\n    ReadPotterAsKid -&gt; ReadingAsAdult\n}\")\n\nplot(dag1)\n\n\n\n\n\n\n\n\n\n\nWhat direct effects should be included when trying to answer your research question of interest?\nWhat indirect effects should be included when trying to answer your research question of interest?\nWhat is a likely alternative explanation of why we might see a relationship between reading Harry Potter and reading more as an adult?\nLikesReading is included as an unobserved variable. Why do we bother to include variables on our diagrams if we can‚Äôt observe them? Why might we think that LikesReading is an unobserved or latent variable?",
    "crumbs": [
      "Causal graph fundamentals"
    ]
  },
  {
    "objectID": "03-causal-graphs-intro.html#warm-up-2",
    "href": "03-causal-graphs-intro.html#warm-up-2",
    "title": "Causal graph fundamentals",
    "section": "Warm-up 2",
    "text": "Warm-up 2\nThe diagram below depicts a cyclical relationship between workplace culture and satisfaction. If employees perceive a more positive workplace culture, their satisfaction at work goes up, and if their satisfaction goes up, they contribute more to a positive workplace culture. Change the diagram so that the relationship is no longer cyclic.\n\n\nCode\ndag2 &lt;- dagitty(\"dag {\n    bb=\\\"0,0,1,1\\\"\n    WorkCulture [pos=\\\"0.250,0.500\\\"]\n    WorkSatisfaction [pos=\\\"0.750,0.500\\\"]\n    WorkCulture &lt;-&gt; WorkSatisfaction\n}\")\n\nplot(dag2)",
    "crumbs": [
      "Causal graph fundamentals"
    ]
  },
  {
    "objectID": "03-causal-graphs-intro.html#warm-up-3",
    "href": "03-causal-graphs-intro.html#warm-up-3",
    "title": "Causal graph fundamentals",
    "section": "Warm-up 3",
    "text": "Warm-up 3\nDo you think it‚Äôs a stronger assumption to include an arrow or exclude an arrow on a causal diagram?",
    "crumbs": [
      "Causal graph fundamentals"
    ]
  },
  {
    "objectID": "03-causal-graphs-intro.html#simplifying-causal-diagrams",
    "href": "03-causal-graphs-intro.html#simplifying-causal-diagrams",
    "title": "Causal graph fundamentals",
    "section": "Simplifying causal diagrams",
    "text": "Simplifying causal diagrams\nThe world is very complex, and causal diagrams can get very complex too.\n\nSimplifying causal diagrams is important for identification: focusing on alternate explanations of consequence.\nSimplifying is also important for sharing the diagram with diverse experts to get good feedback.\n\nWe can use a few techniques to simplify causal diagrams:\n\nUnimportance\n\nVariables that have small effects on all other variables in the diagram and edges with small effects can likely be omitted safely.\ne.g., Living near a quiet cafe affects online course taking\n\nRedundancy\n\nVariables that have the same arrows going in and coming out can be grouped together.\ne.g., Demographic variables like age and race and socioeconomic variables like years of school and years of work experience often have arrows pointing to the outcome and to treatment.\n\nCaveat: Having ‚ÄúDemographic Factors‚Äù and ‚ÄúSocioeconomic Factors‚Äù nodes can simplify the presentation of the causal diagram, but we really do need to know all the individual variables inside these broad categories to accurately estimate causal effects because each variable represents a different alternate explanation.\n\n\nGet rid of mediators\n\nIn situations like A -&gt; B -&gt; C with no other arrows into or out of B, we can likely omit B safely.\nCaveat: In an area called mediation analysis (which aims to estimate the direct and indirect components of an overall causal effect), explicitly including mediators and paying careful attention to how mediators are related to other variables is very important.\n\nIrrelevance\n\nIf a variable isn‚Äôt on any path between the treatment and outcome, we can likely safely omit the variable.\nWe‚Äôll talk more about the rationale for this in the next classes.",
    "crumbs": [
      "Causal graph fundamentals"
    ]
  },
  {
    "objectID": "03-causal-graphs-intro.html#drawing-causal-diagrams-with-dagitty",
    "href": "03-causal-graphs-intro.html#drawing-causal-diagrams-with-dagitty",
    "title": "Causal graph fundamentals",
    "section": "Drawing causal diagrams with DAGitty",
    "text": "Drawing causal diagrams with DAGitty\nDAGitty is an online tool (with an associated R package) for drawing causal diagrams. Click the ‚ÄúLaunch‚Äù link to open a web tool.\n\nModel &gt; New Model: clear the screen\nAdd a node: Click on the gray canvas\nAdd an edge: First click on the variable representing the cause, then the variable representing the effect (arrow points to second node clicked)\nDelete a node: Click a node and hit ‚ÄúD‚Äù. (Or expand the ‚ÄúVariable‚Äù toggle in the top left and check ‚Äúexposure‚Äù.)\nDelete an edge: First click the variable representing the cause, then the variable representing the effect.\nLabel a node as the treatment (exposure): Click a node and hit ‚ÄúE‚Äù. (Or expand the ‚ÄúVariable‚Äù toggle in the top left and check ‚Äúexposure‚Äù.)\nLabel a node as the outcome: Click a node and hit ‚ÄúO‚Äù. (Or expand the ‚ÄúVariable‚Äù toggle in the top left and check ‚Äúoutcome‚Äù.)",
    "crumbs": [
      "Causal graph fundamentals"
    ]
  },
  {
    "objectID": "03-causal-graphs-intro.html#exercise-1",
    "href": "03-causal-graphs-intro.html#exercise-1",
    "title": "Causal graph fundamentals",
    "section": "Exercise 1",
    "text": "Exercise 1\nFor your research question, sketch the possible data-generating process using a causal diagram (on paper or with DAGitty):\n\nClearly indicate the cause of interest and the outcome.\nWrite down other variables are at play in this situation. Include these variables as nodes.\nAdd edges depicting direct causal relationships between variables.\nIndicate which variables are latent or unobserved.\nIndicate which variables might be harder to collect (reliable) data on.",
    "crumbs": [
      "Causal graph fundamentals"
    ]
  },
  {
    "objectID": "03-causal-graphs-intro.html#exercise-2",
    "href": "03-causal-graphs-intro.html#exercise-2",
    "title": "Causal graph fundamentals",
    "section": "Exercise 2",
    "text": "Exercise 2\nYou and your partner will take turns presenting your research question and causal diagram and working together to simplify the diagram.\nPick one person to go first, and go through the following 2 steps. Switch when you‚Äôre done.\nStep 1: Present your research question and causal diagram, making sure to explain any context needed to understand:\n\nThe variables in the diagram\nThe edges in and absent from the diagram\nWhich paths are part of the causal effect of interest\n\nThe listener should ask clarifying questions as necessary.\nStep 2: Together, work through attempting to simplify the presenter‚Äôs diagram by going through the following 4 principles:\n\nUnimportance\nRedundancy\nMediators\nIrrelevance\n\nMake note of what was changed and what you‚Äôre still unsure about. If you came across a good example of one of these principles, draw it on the board to share with the class during our end-of-class debrief.",
    "crumbs": [
      "Causal graph fundamentals"
    ]
  },
  {
    "objectID": "01-introductions.html",
    "href": "01-introductions.html",
    "title": "Introductions and foundational ideas",
    "section": "",
    "text": "Goals\n\nMeet and get to know your peers\nGain an understanding of what this course is about\nReflect on intuitions about causation\nGet acquainted with a framework for thinking about causal effects\n\n\nSlides for today: HTML, PDF",
    "crumbs": [
      "Introductions and foundational ideas"
    ]
  },
  {
    "objectID": "02-identification.html",
    "href": "02-identification.html",
    "title": "Causal identification: building intuition",
    "section": "",
    "text": "Explain what is meant by the term causal identification\nThink about the data-generating process (DGP) in a given context to understand its impact on causal identification\nGet a sense for different approaches to causal identification that we will explore in this course",
    "crumbs": [
      "Causal identification: building intuition"
    ]
  },
  {
    "objectID": "02-identification.html#average-causal-effects",
    "href": "02-identification.html#average-causal-effects",
    "title": "Causal identification: building intuition",
    "section": "Average causal effects",
    "text": "Average causal effects\nSuppose we are studying the effect of a mental health program for expecting mothers and fathers. The treatment is participation in the program vs.¬†not. The outcome is a yes/no occurrence of postpartum depression within the first year of the infant‚Äôs life. We estimate the average causal effect \\(E[Y^{a=1} - Y^{a=0}]\\) to be -0.1.\nHow can we interpret this effect?",
    "crumbs": [
      "Causal identification: building intuition"
    ]
  },
  {
    "objectID": "02-identification.html#research-questions",
    "href": "02-identification.html#research-questions",
    "title": "Causal identification: building intuition",
    "section": "Research questions",
    "text": "Research questions\n\nComing up with a question is easy. Just ask any five-year-old and they can provide you with dozens. Coming up with a good research question is much harder.\nWhat‚Äôs the difference? The difference, at least in the case of quantitative empirical research, is that a research question is a question that can be answered, and for which having that answer will improve your understanding of how the world works.\n\nAsking ‚Äúhow‚Äù (as in ‚Äúhow do we do better?‚Äù) naturally leads to ‚ÄúShould we‚Ä¶‚Äù questions:\n\nHow can we mitigate the effects of climate change?\nShould we implement a plastic tax?",
    "crumbs": [
      "Causal identification: building intuition"
    ]
  },
  {
    "objectID": "02-identification.html#identification-warm-up",
    "href": "02-identification.html#identification-warm-up",
    "title": "Causal identification: building intuition",
    "section": "Identification: warm-up",
    "text": "Identification: warm-up\n\nWhen we say ‚Äúthis variation has identified the effect we‚Äôre interested in‚Äù, which of the following is the best definition of the term identified? Explain why you think your chosen response is the best definition and why the others are not.\n\nWe‚Äôve generated the data by conducting a controlled experiment in which treatment is randomly assigned.\nIn the data generating process, the only reason why we see variation in the outcome variable is because of the treatment variable.\nThe relationship we are looking at in the data actually tests a hypothesis.\nIn the variation we use, there‚Äôs no reason we‚Äôd see any relationship at all except for the effect we‚Äôre interested in.",
    "crumbs": [
      "Causal identification: building intuition"
    ]
  },
  {
    "objectID": "02-identification.html#isolating-variation",
    "href": "02-identification.html#isolating-variation",
    "title": "Causal identification: building intuition",
    "section": "Isolating variation",
    "text": "Isolating variation\nExample: A child‚Äôs shoe size is a great predictor of their reading ability\n\nWe can quantify covariation in shoe size and reading ability with measures like the correlation coefficient, slope and its confidence interval\nWhen we think about the underlying data-generating process, we see that the totality of this covariation also encompasses the covariation in:\n\nage and shoe size\nage and reading ability\n\nWe can isolate a part of this covariation by holding age constant and then looking at the relationship between shoe size and reading ability\n\n\\(E[ReadingAbility \\mid ShoeSize, Age] = \\beta_0 + \\beta_1 ShoeSize + \\beta_2 Age\\)\n\n\nThere are other ways to isolate variation that we will explore today and throughout the semester.",
    "crumbs": [
      "Causal identification: building intuition"
    ]
  },
  {
    "objectID": "02-identification.html#exercise-1",
    "href": "02-identification.html#exercise-1",
    "title": "Causal identification: building intuition",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe are interested in the effect of mindful breathing practices on stress levels.\n\nPart a\nSuppose we tried to estimate this effect by surveying people at Macalester. We ask them if they engage regularly in mindful breathing practices and to report their general stress levels on a 1-10 scale (1 = lowest stress, 10 = highest stress).\nDo you think we would be identifying the causal effect by comparing the mean stress levels in those who do regularly use mindful breathing with those who don‚Äôt? What aspects of the data generating process (DGP) are relevant for your response?\n\n\nPart b\nNow suppose that we were able to find 500 people with a self-reported stress level of 6 who don‚Äôt already engage in mindful breathing. The Hamre Center has resources to enroll 250 people in a 3-month mindful breathing program. They decide to randomly select the 250 participants from the 500 and measure the stress levels of all 500 people after the 3-month program.\nDo you think we would we be identifying the causal effect by comparing the mean stress levels after 3 months in those enrolled in the program with those who weren‚Äôt enrolled? What aspects of the data generating process (DGP) are relevant for your response?",
    "crumbs": [
      "Causal identification: building intuition"
    ]
  },
  {
    "objectID": "02-identification.html#exercise-2",
    "href": "02-identification.html#exercise-2",
    "title": "Causal identification: building intuition",
    "section": "Exercise 2",
    "text": "Exercise 2\nWe notice that ice cream sales in St.¬†Paul are correlated with the percentage of the population wearing shorts and wonder if there is a causal relationship between the two.\n\nPart a\nIn this context, what aspects of the data generating process do you think are most important to keep in mind? What alternative explanations can you come up with?\n\n\nPart b\nRecall that the main idea with identification is to find variation that we want to use and get rid of variation that we don‚Äôt want.\nFor this context, a number of plots and linear regression model output are shown below. Explain how these results show desired variation, undesired variation, and the process of identification by getting rid of undesired variation.\n\n\nCode\nset.seed(451)\nice_cream_data &lt;- tibble(\n    temp = rep(0:90, each = 4),\n    perc_shorts = case_when(\n        temp &lt; 40 ~ 3*sqrt(temp) + 10, \n        temp &gt;= 40 & temp &lt; 65 ~ 1.5*temp - 30,\n        temp &gt;= 65 ~ temp + 9\n    ),\n    ice_cream_sales = log(temp+1)^2 + 100 + rnorm(364, 0, 10)\n) %&gt;% \n    mutate(\n        perc_shorts = perc_shorts + rnorm(364, 0, 2),\n        perc_shorts = pmax(perc_shorts, 10),\n        perc_shorts = pmin(perc_shorts, 98)\n    )\n\n\n\n\nCode\nggplot(ice_cream_data, aes(x = perc_shorts, y = ice_cream_sales)) +\n    geom_point() +\n    geom_smooth(se = FALSE) +\n    labs(x = \"% of St. Paul wearing shorts\", y = \"Ice cream sales ($10's)\") +\n    theme_classic()\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nCode\nggplot(ice_cream_data, aes(x = temp, y = perc_shorts)) +\n    geom_point() +\n    labs(x = \"Temperature (F)\", y = \"% of St. Paul wearing shorts\") +\n    theme_classic()\n\n\n\n\n\n\n\n\n\nCode\nggplot(ice_cream_data, aes(x = temp, y = ice_cream_sales)) +\n    geom_point() +\n    geom_smooth(se = FALSE) +\n    labs(x = \"Temperature (F)\", y = \"Ice cream sales ($10's)\") +\n    theme_classic()\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nCode\nlm(ice_cream_sales ~ perc_shorts, data = ice_cream_data) %&gt;% summary()\n\n\n\nCall:\nlm(formula = ice_cream_sales ~ perc_shorts, data = ice_cream_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.941  -6.820   0.384   6.448  29.639 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 104.57894    1.04068 100.491   &lt;2e-16 ***\nperc_shorts   0.18668    0.01886   9.896   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.931 on 362 degrees of freedom\nMultiple R-squared:  0.2129,    Adjusted R-squared:  0.2108 \nF-statistic: 97.93 on 1 and 362 DF,  p-value: &lt; 2.2e-16\n\n\nCode\nlm(ice_cream_sales ~ perc_shorts + temp, data = ice_cream_data) %&gt;% summary()\n\n\n\nCall:\nlm(formula = ice_cream_sales ~ perc_shorts + temp, data = ice_cream_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-30.9542  -6.6926  -0.0641   6.3933  28.0907 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 104.26394    1.02618 101.603  &lt; 2e-16 ***\nperc_shorts  -0.06449    0.07000  -0.921  0.35748    \ntemp          0.27363    0.07354   3.721  0.00023 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.76 on 361 degrees of freedom\nMultiple R-squared:  0.242, Adjusted R-squared:  0.2378 \nF-statistic: 57.63 on 2 and 361 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Causal identification: building intuition"
    ]
  },
  {
    "objectID": "02-identification.html#exercise-3",
    "href": "02-identification.html#exercise-3",
    "title": "Causal identification: building intuition",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe are interested in the effect of a r√©sum√© writing workshop (Treatment) on adults‚Äô ability to secure a new job (Outcome). Suppose that we have thought carefully about the data-generating process and determined that age, education level, income, employment status, and marital status are the most important factors in alternative explanations.\n\nPart a\nWe have data on 10 adults (5 who took the workshop, and 5 who didn‚Äôt):\n\n\nCode\n# Create the example dataset\ndata &lt;- tibble::tribble(\n  ~ID, ~Age, ~Education, ~Income, ~Employment, ~MaritalStatus, ~Treatment, ~Outcome,\n  1, 25, \"HighSchool\", \"Low\", \"Employed\", \"Single\", 1, 0,\n  2, 30, \"College\", \"Medium\", \"Employed\", \"Married\", 1, 1,\n  3, 28, \"HighSchool\", \"Low\", \"Unemployed\", \"Single\", 1, 0,\n  4, 35, \"College\", \"High\", \"Employed\", \"Married\", 1, 1,\n  5, 40, \"College\", \"High\", \"Unemployed\", \"Married\", 1, 0,\n  6, 22, \"HighSchool\", \"Low\", \"Employed\", \"Single\", 0, 1,\n  7, 30, \"HighSchool\", \"Medium\", \"Unemployed\", \"Married\", 0, 0,\n  8, 45, \"College\", \"High\", \"Employed\", \"Single\", 0, 1,\n  9, 50, \"HighSchool\", \"Low\", \"Employed\", \"Single\", 0, 0,\n  10, 30, \"College\", \"Medium\", \"Employed\", \"Married\", 0, 1\n)\n\n# Display the dataset\ndata\n\n\n# A tibble: 10 √ó 8\n      ID   Age Education  Income Employment MaritalStatus Treatment Outcome\n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt;\n 1     1    25 HighSchool Low    Employed   Single                1       0\n 2     2    30 College    Medium Employed   Married               1       1\n 3     3    28 HighSchool Low    Unemployed Single                1       0\n 4     4    35 College    High   Employed   Married               1       1\n 5     5    40 College    High   Unemployed Married               1       0\n 6     6    22 HighSchool Low    Employed   Single                0       1\n 7     7    30 HighSchool Medium Unemployed Married               0       0\n 8     8    45 College    High   Employed   Single                0       1\n 9     9    50 HighSchool Low    Employed   Single                0       0\n10    10    30 College    Medium Employed   Married               0       1\n\n\nFor case 2, we observe the potential outcome under treatment \\(Y^{a=1}\\). Do you think that we might be able to directly guess this unit‚Äôs counterfactual outcome \\(Y^{a=0}\\) by using information from another case? Why or why not? \nWhat about for case 1? \n\n\nPart b\nThinking about the process that you went through in part (a), do you think this process gets easier with more variables? Why or why not?\n\n\n\n\n\n\nExercise 3 context (read after completion)\n\n\n\n\n\nI used ChatGPT to generate the example dataset in Part a. This is the prompt I used:\n\nCan you give me an example dataset with 10 cases that has one age variable, 4 categorical socioeconomic variables, and one binary outcome variable? This dataset is intended to provide an example of the matching causal inference method to students. This dataset should have some exact and approximate matches.",
    "crumbs": [
      "Causal identification: building intuition"
    ]
  },
  {
    "objectID": "02-identification.html#exercise-4",
    "href": "02-identification.html#exercise-4",
    "title": "Causal identification: building intuition",
    "section": "Exercise 4",
    "text": "Exercise 4\nThe following 2 figures come from a study of the effect of attending a state flagship university on earnings a few years after college graduation. Flagship state universities tend to be the premier public colleges in the state. They are often the first college to have been established in the state and the most research-intensive with more resources.\nIn the first figure, the x-axis indicates the number of SAT points away from the admissions cutoff for the state flagship (a recentered SAT score). (The cutoff is a strongly suggested but not a hard cutoff for admission.) Each point shows the enrollment rate at the flagship university for that recentered SAT score. The solid lines show nonlinear trends fitted separately to the left and to the right of x=0. The t=10.57 indicates a test statistic for a hypothesis test on the jump at x=0.\n\nIn the second figure, the x-axis is the same, and the y-axis represents the natural log earnings after calendar year, years of work experience, and graduation year have been accounted for (which is what the ‚Äú(Residual)‚Äù part of the axis label is indicating). (More details are described in this section of our Mixtape textbook.) The z=3.01 indicates a test statistic for a hypothesis test on the jump at x=0.\n\n\nWhat story do you think the author is trying to tell with these figures?\nIf the admissions cutoff did not exist, what do you think the relationship between enrollment rate and SAT points would look like? What about the relationship between earnings and SAT points?\nHow different do you think students just below and just above the admission cutoff are? How could this be helpful in isolating only desired variation?",
    "crumbs": [
      "Causal identification: building intuition"
    ]
  },
  {
    "objectID": "02-identification.html#exercise-5",
    "href": "02-identification.html#exercise-5",
    "title": "Causal identification: building intuition",
    "section": "Exercise 5",
    "text": "Exercise 5\nThis paper looked at the effect of Florida‚Äôs 2005 ‚ÄúStand Your Ground‚Äù (SYG) law on homicide rates. The law gave citizens the right to use lethal force in self-defense in public places where they felt threatened.\nTake a look at panel A from this figure from the paper which shows homicide rates in Florida and comparison states over time.\n\nWhat story do you think the author is trying to tell with this figure?\nDo you think that the trends in homicide rates in Florida and the comparison states are similar before the SYG law was enacted in 2005? Why might similarity be desirable?\nDraw or describe what you guess might have happened in Florida had it not enacted the SYG law. How is this related to identification of the causal effect of the SYG law on homicide rates?",
    "crumbs": [
      "Causal identification: building intuition"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html",
    "href": "04-causal-graphs-simulation.html",
    "title": "Simulating data using causal graphs",
    "section": "",
    "text": "library(tidyverse)\nlibrary(scales)\nlibrary(broom)\nlibrary(dagitty)",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html#structure-of-causal-graphs",
    "href": "04-causal-graphs-simulation.html#structure-of-causal-graphs",
    "title": "Simulating data using causal graphs",
    "section": "Structure of causal graphs",
    "text": "Structure of causal graphs\nThe fact that causal graphs depict a data-generating process means that it conveys statistical information about the relationships between variables.\n3 structures form the basis of every pattern in a causal graph:\n\nChains: A -&gt; B -&gt; C\nForks: A &lt;- B -&gt; C (B is a common cause)\nColliders: A -&gt; B &lt;- C (B is a common effect)",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html#examples",
    "href": "04-causal-graphs-simulation.html#examples",
    "title": "Simulating data using causal graphs",
    "section": "Examples",
    "text": "Examples\nNote: I asked ChatGPT to help me generate examples of these structures in different contexts with the following prompt:\n\nGive me an example of a [chain,fork,collider] causal graph structure in the following contexts: mental health, sociology, biology, medicine, public health, economics, politics.\n\nChains:\n\nMental Health: Childhood Trauma -&gt; Depression -&gt; Substance Abuse\nSociology: Education Level -&gt; Employment Status -&gt; Income Level\nBiology: Gene Mutation -&gt; Protein Dysfunction -&gt; Disease Onset\nMedicine: Infection -&gt; Immune Response -&gt; Fever\nPublic Health: Air Pollution -&gt; Respiratory Problems -&gt; Hospital Admissions\nEconomics: Interest Rate Changes -&gt; Investment Levels -&gt; Economic Growth\nPolitics: Political Campaign -&gt; Public Opinion -&gt; Election Outcome\n\nForks:\n\nMental Health: Depression &lt;- Genetic Predisposition -&gt; Anxiety\nSociology: Children‚Äôs Socioeconomic Status &lt;- Parental Education Level -&gt; Children‚Äôs Educational Attainment\nBiology: Weight Gain &lt;- Hormonal Imbalance -&gt; Fatigue\nMedicine: Cardiovascular Disease &lt;- Poor Diet -&gt; Obesity\nPublic Health: Health Outcomes &lt;- Socioeconomic Status -&gt; Access to Healthcare\nEconomics: Consumer Spending &lt;- Economic Recession -&gt; Unemployment Rates\nPolitics: Voting Behavior &lt;- Political Polarization -&gt; Media Consumption\n\nColliders:\n\nMental Health: Genetic Predisposition -&gt; Depression &lt;- Life Stressors\nSociology: Educational Attainment -&gt; Income Level &lt;- Social Network\nBiology: Gene Mutation -&gt; Disease Onset &lt;- Environmental Factors\nMedicine: Lack of Physical Activity -&gt; Obesity &lt;- Poor Diet\nPublic Health: Air Pollution -&gt; Respiratory Problems &lt;- Smoking\nEconomics: Economic Policies -&gt; Inflation Rate &lt;- Global Market Conditions\nPolitics: Campaign Funding -&gt; Election Outcome &lt;- Public Opinion",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html#marginal-and-conditional-independence-in-causal-graphs",
    "href": "04-causal-graphs-simulation.html#marginal-and-conditional-independence-in-causal-graphs",
    "title": "Simulating data using causal graphs",
    "section": "Marginal and conditional (in)dependence in causal graphs",
    "text": "Marginal and conditional (in)dependence in causal graphs\n\nChains, forks, and colliders have different patterns of marginal and conditional independence and dependence.\nThese patterns are the core of what makes something an alternate explanation and how we can address that alternate explanation through analysis (coming next time).\nThe marginal/conditional (in)dependence properties are not intuitive, but we can see them play out via simulation.",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html#simulation",
    "href": "04-causal-graphs-simulation.html#simulation",
    "title": "Simulating data using causal graphs",
    "section": "Simulation",
    "text": "Simulation\n\nWhen conducting simulations, we are in control of the data-generating process.\nWe control the distribution of all variables and how they are related to each other.\nWe can simulate data from a causal graph by:\n\nSimulate variables that don‚Äôt have causes (called exogenous variables)\n\nExample: In the chain X -&gt; Y -&gt; Z, we would simulate X first.\n\nSimulate the variables caused by the exogenous variables. Then simulate the variables caused by these variables, etc.\n\nExample: In the chain X -&gt; Y -&gt; Z, after simulating X, simulate Y then Z.",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html#simulating-quantitative-and-categorical-variables",
    "href": "04-causal-graphs-simulation.html#simulating-quantitative-and-categorical-variables",
    "title": "Simulating data using causal graphs",
    "section": "Simulating quantitative and categorical variables",
    "text": "Simulating quantitative and categorical variables\nThis table at the end of our reading provides a nice summary of simulation functions.\nFor quantitative variables we can use:\n\nrnorm()\nrunif()\nrescale() (This function is part of the scales package.)\n\nFor categorical variables we can use:\n\nrbinom(): For binary variables\nsample(): For 3+ categories\n\nWe can look up the documentation for functions by entering ?function_name in the Console. Use the documentation for these functions to complete the following exercises:\n\n# Set seed for random number generator for reproducible results\nset.seed(451)\n\n# Simulate 1000 normally distributed numbers with mean 10 and standard deviation 2. Store as variable X\nX &lt;- \n\n# Check distribution of X with a plot (code is complete)\nggplot(data.frame(X), aes(x = X)) +\n    geom_histogram()\n\n# Simulate 1000 uniformly distributed numbers between 10 and 20. Store as variable Y\nY &lt;- \n\n# Check distribution of Y with a plot (code is complete)\nggplot(data.frame(Y), aes(x = Y)) +\n    geom_histogram()\n\n\n# Rescale X to be between 0 and 1. Store as variable Z\nZ &lt;- \n\n# Check distribution of Y with a plot (code is complete)\nggplot(data.frame(Z), aes(x = Z)) +\n    geom_histogram()",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html#simulating-dependence",
    "href": "04-causal-graphs-simulation.html#simulating-dependence",
    "title": "Simulating data using causal graphs",
    "section": "Simulating dependence",
    "text": "Simulating dependence\nWe can use regression model formulas to have the mean of a variable depend on its causes.\nFor the mean of quantitative variables:\n\\[\nE[\\text{score} \\mid \\text{hoursPractice}, \\text{reviewSession}] = 40 + 3\\times\\text{hoursPractice} + 10\\times \\text{reviewSessionYes}\n\\] The mean of a binary (0/1) variable is the probability that it equals 1. We can use a similar regression model formula to determine this probability and use rescale() to force this number to be between 0 and 1.",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html#example",
    "href": "04-causal-graphs-simulation.html#example",
    "title": "Simulating data using causal graphs",
    "section": "Example",
    "text": "Example\nWe‚Äôll simulate data from this causal graph:\n\ndag &lt;- dagitty(\"dag {\nbb=\\\"0,0,1,1\\\"\n3MonthStress [outcome,pos=\\\"0.800,0.500\\\"]\nMindfulBreathing [exposure,pos=\\\"0.200,0.500\\\"]\nPriorStress [pos=\\\"0.400,0.250\\\"]\nYoga [pos=\\\"0.600,0.250\\\"]\nMindfulBreathing -&gt; 3MonthStress\nPriorStress -&gt; 3MonthStress\nPriorStress -&gt; MindfulBreathing\nYoga -&gt; 3MonthStress\nYoga -&gt; MindfulBreathing\n}\")\nplot(dag)\n\n\n\n\n\n\n\n\nSimulation code:\n\nset.seed(451)\nn &lt;- 1000\nsim_data &lt;- tibble(\n    prior_stress = runif(n, min = 0, max = 10),\n    yoga = rbinom(n, size = 1, prob = 0.15),\n    p_mindful_breathing = rescale(1 + 3*prior_stress + 25*yoga, to = c(0,1)),\n    mindful_breathing = rbinom(n, size = 1, prob = p_mindful_breathing),\n    mean_stress_3_month = prior_stress - 3*yoga - 5*mindful_breathing,\n    noise_stress_3_month = rnorm(n, mean = 0, sd = 2),\n    stress_3_month = mean_stress_3_month + noise_stress_3_month\n)\n\nIt‚Äôs important to use plots and models to check the relationships in the data we generated:\n\nggplot(sim_data, aes(x = factor(mindful_breathing), y = prior_stress)) +\n    geom_boxplot()\n\n\n\n\n\n\n\nggplot(sim_data, aes(x = factor(mindful_breathing), fill = factor(yoga))) +\n    geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nmod &lt;- lm(stress_3_month ~ yoga + prior_stress + mindful_breathing, data = sim_data)\nsummary(mod)\n\n\nCall:\nlm(formula = stress_3_month ~ yoga + prior_stress + mindful_breathing, \n    data = sim_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.1686 -1.2857 -0.0591  1.2766  7.5840 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.1353     0.1285   1.053    0.293    \nyoga               -2.7436     0.1903 -14.416   &lt;2e-16 ***\nprior_stress        0.9931     0.0235  42.259   &lt;2e-16 ***\nmindful_breathing  -5.1820     0.1475 -35.131   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.943 on 996 degrees of freedom\nMultiple R-squared:  0.7494,    Adjusted R-squared:  0.7487 \nF-statistic:   993 on 3 and 996 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html#long-run-properties-via-simulation",
    "href": "04-causal-graphs-simulation.html#long-run-properties-via-simulation",
    "title": "Simulating data using causal graphs",
    "section": "Long-run properties via simulation",
    "text": "Long-run properties via simulation\nSuppose that X and Y are independent quantitative variables. Suppose that we fit the model below:\n\\[E[Y \\mid X] = \\beta_0 + \\beta_1 X\\]\n\nLet our significance level (type I error rate) be 0.05. What would you expect about the p-value for the coefficient on X?\nNow suppose that you have 1000 different samples of X and Y and fit the above model on each sample. What would you expect about the 1000 p-values?\n\n\n\n\n\n\n\nResponse\n\n\n\n\n\nIf X and Y are independent, the null hypothesis \\(H_0: \\beta_1 = 0\\) is true. A significance level (type I error rate) of 0.05 means that we‚Äôre choosing our test statistic threshold to be high enough that, if the null hypothesis were true, we would (incorrectly) reject the null 5% of the time.\nWe reject the null when p-value &lt; 0.05. Since the null is true in this case, this will happen (p-value &lt; 0.05) in 5% of samples. So we‚Äôre expecting 50 of the 1000 samples to give p-values less than 0.05.",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html#exercise-1-chains",
    "href": "04-causal-graphs-simulation.html#exercise-1-chains",
    "title": "Simulating data using causal graphs",
    "section": "Exercise 1: chains",
    "text": "Exercise 1: chains\nIn the code chunk below, write code to simulate a single dataset from the following chain:\nAge -&gt; Total hours reading practice -&gt; Reading ability\n\n# Simulate data from the chain\n# Store data in a dataset called sim_data_chain\n# Call your variables age, practice_hrs, read_ability\n\n\n# Use plots to verify that univariate distributions look ok and that the direct causal relationships look right\n\nCopy and paste the code that creates the sim_data_chain dataset into the space indicated in the function below. Then complete the next block of code to fit an appropriate model for checking how age and reading ability are related conditional on hours of practice. The remainder of the code looks at the p-values from 1000 simulations.\n\nsimulate_chain &lt;- function() {\n    n &lt;- 10000\n    # Paste your code for creating your simulated chain data here\n    sim_data_chain &lt;- ___\n    \n    # Fit a linear regression model that allows you to see \n    # the relationship between read_ability and age \n    # conditional on practice_hrs\n    mod &lt;- ___\n    \n    # Pull out the p-value for the age coefficient\n    tidy(mod) %&gt;% \n        filter(term==\"age\") %&gt;% \n        pull(p.value)\n}\n\n# Repeat the simulation 1000 times (generate 1000 datasets)\nset.seed(451)\nsystem.time({\nchain_pvals &lt;- replicate(1000, {\n    simulate_chain()\n})\n})\n\n# How many times were the p-values less than 0.05?\n# Is this what you expected?\ntable(chain_pvals &lt; 0.05)",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html#exercise-2-forks",
    "href": "04-causal-graphs-simulation.html#exercise-2-forks",
    "title": "Simulating data using causal graphs",
    "section": "Exercise 2: forks",
    "text": "Exercise 2: forks\nIn the code chunk below, write code to simulate a single dataset from the following fork:\n% of population wearing shorts &lt;- Temperature -&gt; Ice cream sales\n\n# Simulate data from the fork\n# Store data in a dataset called sim_data_fork\n# Call your variables perc_shorts, temperature, ice_cream_sales\n\n\n# Use plots to verify that univariate distributions look ok and that the direct causal relationships look right\n\nCopy and paste the code that creates the sim_data_fork dataset into the space indicated in the function below. Then complete the next block of code to fit an appropriate model for checking how age and reading ability are related conditional on hours of practice. The remainder of the code looks at the p-values from 1000 simulations.\n\nsimulate_fork &lt;- function() {\n    n &lt;- 10000\n    # Paste your code for creating your simulated fork data here\n    sim_data_fork &lt;- ___\n    \n    # Fit a linear regression model that allows you to see \n    # the relationship between % shorts and ice cream sales\n    # conditional on temperature\n    mod &lt;- ___\n    \n    # Pull out the p-value for the perc_shorts coefficient\n    tidy(mod) %&gt;% \n        filter(term==\"perc_shorts\") %&gt;% \n        pull(p.value)\n}\n\n# Repeat the simulation 1000 times (generate 1000 datasets)\nset.seed(451)\nsystem.time({\nfork_pvals &lt;- replicate(1000, {\n    simulate_fork()\n})\n})\n\n# How many times were the p-values less than 0.05?\n# Is this what you expected?\ntable(fork_pvals &lt; 0.05)",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html#exercise-3-colliders",
    "href": "04-causal-graphs-simulation.html#exercise-3-colliders",
    "title": "Simulating data using causal graphs",
    "section": "Exercise 3: colliders",
    "text": "Exercise 3: colliders\nIn the code chunk below, write code to simulate a single dataset from the following collider:\nSmoking -&gt; Hospitalization &lt;- COVID-19 Infection\n\n# Simulate data from the collider\n# Store data in a dataset called sim_data_collider\n# Call your variables covid, hosp, smoking\n\n\n# Use plots to verify that univariate distributions look ok and that the direct causal relationships look right\n# Also use a plot and/or model to verify the marginal relationship between covid and smoking\n\nCopy and paste the code that creates the sim_data_collider dataset into the space indicated in the function below. Then complete the next block of code to fit an appropriate model for checking how age and reading ability are related conditional on hours of practice. The remainder of the code looks at the p-values from 1000 simulations.\n\nNote: You may have to increase the magnitude of the smoking -&gt; hosp effect and the magnitude of the covid -&gt; hosp effect to see the expected behavior.\nIf you end up updating the numbers in your model formulas in light of the above note, try adding arguments to your function like this:\n\nsimulate_collider &lt;- function(smoking_effect, covid_effect)\nThis allows smoking_effect and covid_effect to be inputs to your function. Replace the appropriate numbers in your sim_data_collider code to use smoking_effect and covid_effect.\nYou‚Äôll then need to update the 1000 simulations part to something like:\n\n\nset.seed(451)\nsystem.time({\ncollider_pvals &lt;- replicate(1000, {\n    simulate_collider(smoking_effect = 10, covid_effect = 10)\n})\n})\n\nsimulate_collider &lt;- function() {\n    n &lt;- 10000\n    # Paste your code for creating your simulated collider data here\n    sim_data_collider &lt;- ___\n    \n    # Fit a linear regression model that allows you to see \n    # the relationship between smoking and covid\n    # conditional on hospitalization\n    mod &lt;- ___\n    \n    # Pull out the p-value for the smoking coefficient\n    tidy(mod) %&gt;% \n        filter(term==\"smoking\") %&gt;% \n        pull(p.value)\n}\n\n# Repeat the simulation 1000 times (generate 1000 datasets)\nset.seed(451)\nsystem.time({\ncollider_pvals &lt;- replicate(1000, {\n    simulate_collider()\n})\n})\n\n# How many times were the p-values less than 0.05?\n# Is this what you expected?\ntable(collider_pvals &lt; 0.05)",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "04-causal-graphs-simulation.html#exercise-4-beyond-building-blocks",
    "href": "04-causal-graphs-simulation.html#exercise-4-beyond-building-blocks",
    "title": "Simulating data using causal graphs",
    "section": "Exercise 4: beyond building blocks",
    "text": "Exercise 4: beyond building blocks\nCan we extend building block thinking to longer, more complex structures? Let‚Äôs investigate here (conceptually, no simulation).\n\nConsider the longer structure A &lt;- B &lt;- C -&gt; D. What do you expect about marginal/conditional (in)dependence of A and D? Explain.\nConsider the longer structure A -&gt; B &lt;- C &lt;- D -&gt; E. What do you expect about marginal/conditional (in)dependence of A and E? Explain.",
    "crumbs": [
      "Simulating data using causal graphs"
    ]
  },
  {
    "objectID": "06-causal-graphs-testing.html",
    "href": "06-causal-graphs-testing.html",
    "title": "Testing causal graphs",
    "section": "",
    "text": "Evaluate the accuracy of a causal graph by testing the conditional independencies implied by the graph structure.\n\n\nYou can download a template file for this activity here.",
    "crumbs": [
      "Testing causal graphs"
    ]
  },
  {
    "objectID": "06-causal-graphs-testing.html#exercise-1",
    "href": "06-causal-graphs-testing.html#exercise-1",
    "title": "Testing causal graphs",
    "section": "Exercise 1",
    "text": "Exercise 1\nHere we‚Äôll look at biological data from a protein interaction network. Take a peek at the data below:\n\nprotein_data &lt;- read_csv(\"https://raw.githubusercontent.com/ankurankan/2020-dagitty-manual/master/protocol3/protein_signal.csv\")\n\n# Randomly subset protein_data to 1000 cases \n# to speed up subsequent computations\nset.seed(451)\nprotein_data_subs &lt;- slice_sample(protein_data, n = 1000)\n\nhead(protein_data_subs)\n\nThe hypothesized causal graph is below.\n\nNote: If the graph looks cut off in RStudio, you can also paste the dag { ... } portion into DAGitty web interface in the ‚ÄúModel code‚Äù pane on the right.\n\n\nprotein_dag &lt;- dagitty('dag {\nbb=\"-0.5,-0.5,0.5,0.5\"\nAkt [pos=\"-0.115,0.052\"]\nErk [pos=\"-0.061,-0.001\"]\nJnk [pos=\"-0.208,-0.149\"]\nMek [pos=\"-0.063,-0.096\"]\nP38 [pos=\"-0.155,-0.141\"]\nPIP2 [pos=\"-0.337,0.063\"]\nPIP3 [pos=\"-0.278,-0.068\"]\nPKA [pos=\"-0.127,-0.200\"]\nPKC [pos=\"-0.111,-0.287\"]\nPlcg [pos=\"-0.337,-0.177\"]\nRaf [pos=\"-0.066,-0.204\"]\nMek -&gt; Erk\nPIP2 -&gt; PKC [pos=\"-0.489,-0.417\"]\nPIP3 -&gt; Akt\nPIP3 -&gt; PIP2\nPIP3 -&gt; Plcg\nPKA -&gt; Akt\nPKA -&gt; Erk\nPKA -&gt; Jnk\nPKA -&gt; Mek\nPKA -&gt; P38\nPKA -&gt; Raf\nPKC -&gt; Jnk [pos=\"-0.188,-0.258\"]\nPKC -&gt; Mek [pos=\"-0.021,-0.245\"]\nPKC -&gt; P38 [pos=\"-0.166,-0.227\"]\nPKC -&gt; Raf\nPlcg -&gt; PIP2\nPlcg -&gt; PKC [pos=\"-0.248,-0.271\"]\nRaf -&gt; Mek\n}')\nplot(protein_dag)\n\nThe code below creates a scatterplot matrix that shows the relationship between each pair of variables using a scatterplot. For example, the plot in row 1, column 2 plots the Raf protein abundance vs.¬†Mek protein abundance. The numbers in the lower triangle give the correlation coefficient between the two variables.\nBased on this plot, what should the type argument be when you run conditional independence tests with localTests()?\n\npanel.cor &lt;- function(x, y) {\n    par(usr = c(0, 1, 0, 1))\n    r &lt;- cor(x, y)\n    txt &lt;- format(r, digits = 2)\n    txt &lt;- str_c(\"Cor: \", txt)\n    text(0.5, 0.5, txt)\n}\n\npairs(protein_data_subs, upper.panel = panel.smooth, lower.panel = panel.cor)\n\nBelow we use impliedConditionalIndependencies() to get a list of testable implications. This time we use type = \"missing.edge\" instead of type = \"all.pairs\".\n\nBecause this graph is so much more complex, checking for conditional independence between all pairs of variables results in a ton of conditional independence statements. (In fact, there are 7182 of them.)\nWhen using ‚Äúmissing.edge‚Äù we focus on conditional independencies that arise from a missing edge between two variables. This results in a much more manageable set of conditional independence statements to test.\n\n\nprotein_dag_cis &lt;- impliedConditionalIndependencies(protein_dag, type = \"missing.edge\")\n\nIn the code chunk below, use the appropriate type argument in localTests() to perform the CI tests.\n\nNote: The R = 100 argument is needed for this type to set the number of bootstrapping iterations for obtaining the confidence interval.\n\n\n# Obtain and display a data frame of CI test results\n# We use a subset of the protein data for computational time reasons\n# The system.time() function measures how long a command takes to run\nsystem.time({\nprotein_dag_ci_test_res &lt;- localTests(protein_dag, data = protein_data_subs, tests = protein_dag_cis, type = ___, R = 100)\n})\n\nprotein_dag_ci_test_res\n\nWe can plot the results of these tests with the plotLocalTestResults() function from dagitty. Based on these results, what modifications to the graph should we investigate first?\n\n# Sort the data frame by the magnitude of the estimate\n# and plot the test statistics (points) and\n# 95% confidence intervals (horizontal bars)\n# Just below this code chunk on the right, click the\n# leftmost white button to open a zoomed window of the plot\nprotein_dag_ci_test_res %&gt;%\n    arrange(abs(estimate)) %&gt;% \n    plotLocalTestResults()",
    "crumbs": [
      "Testing causal graphs"
    ]
  },
  {
    "objectID": "06-causal-graphs-testing.html#exercise-2",
    "href": "06-causal-graphs-testing.html#exercise-2",
    "title": "Testing causal graphs",
    "section": "Exercise 2",
    "text": "Exercise 2\nHere you‚Äôll draw a causal graph for a particular context and test/update your graph based on conditional independence testing.\nFirst navigate to this page, and choose one of the following datasets by exploring the associated codebook:\n\nElection Data - County\nFEV (Lung Function) and Smoking\nHome Sales in NY\n\nRead in the chosen dataset, and take a look at the data by entering View(dataset_name) in the Console.\n\nelection &lt;- read_csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n# Read in and process FEV data\nlungs &lt;- read_csv(\"https://mac-stat.github.io/data/fev.csv\")\nlungs &lt;- lungs %&gt;% \n    # Recode sex and smoke as 0/1 variables\n    mutate(\n        sexFemale = ifelse(sex==\"female\", 1, 0),\n        smoke = ifelse(smoke==\"smoker\", 1, 0)\n    ) %&gt;% \n    select(-sex)\n\n# Read in and process the homes data\nhomes &lt;- read_csv(\"https://mac-stat.github.io/data/homes.csv\")\nhomes &lt;- homes %&gt;% \n    select(-c(Fuel.Type, Heat.Type, Sewer.Type))\n\nDraw a causal graph using DAGitty. If you include variables in your graphs that are not in the data, mark them as unmeasured by clicking the variable and then hitting ‚Äúu‚Äù or checking the ‚Äúunobserved‚Äù checkbox in the top left.\nPaste all the code from the ‚ÄúModel code‚Äù pane below.\n\ndag &lt;- dagitty('\nPaste your dag { ... } here\n')\nplot(dag)\n\nUse impliedConditionalIndependencies() to generate a list of testable implications:\n\nIf you have unmeasured variables in your graph, use type = \"missing.edge\" to ensure that no conditional independencies involving those unmeasured variables are returned. (While these CIs are real implications about your graph, they‚Äôre not testable.)\nOtherwise use type = \"all.pairs\".\n\n\ndag_cis &lt;- impliedConditionalIndependencies(dag, type = ___)\ndag_cis\n\nUse localTests() to test your graph. Inspect the resulting table of test results and, if desired, the plot form with plotLocalTestResults(). Is your graph consistent with the data? What updates might you make?\n\nsystem.time({\ndag_ci_test_res &lt;- localTests(___)\n})\ndag_ci_test_res",
    "crumbs": [
      "Testing causal graphs"
    ]
  },
  {
    "objectID": "08-target-trial.html",
    "href": "08-target-trial.html",
    "title": "Target trial framework",
    "section": "",
    "text": "Goals\n\nCommunicate benefits of using the target trial framework to design the analysis of an observational study\nPractice the process of reading an academic journal article\n\n\n\n\nDiscussion\nThe following prompts are adapted from the following guides for reading scholarly articles:\n\nBrown University‚Äôs guide How to Read a Scholarly Article\nHow to Read the Statistical Methods Literature: A Guide for Students\n\nRead through the following prompts, and then open this Google Doc to record notes as you re-engage with today‚Äôs article: Specifying a target trial prevents immortal time bias and other self-inflicted injuries in observational analyses.\n\nReread the title, abstract, keywords, and introduction\n\nBased on this information, write a 2 sentence description of the problem the article is trying to address.\n\nMake note of the authors\n\nYou might see the same authors repeatedly when exploring other articles referenced in the article. This helps you understand the breadth of topics that certain authors write about.\n\nFind a problem or context that you are familiar with and relate the article‚Äôs arguments to this context.\n\nFor example, it could help to start with the context of a randomized experiment. As you read, ask yourself ‚ÄúWhat is different about the target trial approach?‚Äù\n\nAs you skim the article again:\n\nWrite down unfamiliar jargon to look up later. If a sentence makes a claim that is hard to understand, try to find another concept or term in that sentence or in a nearby sentence that you do understand.\nIf an unfamiliar concept is linked to a citation, write down that citation and categorize that citation as essential (top priority for what to read next) or secondary.\n\nAs you reread the article:\n\nWhat arguments were hard to follow?\nWhat could the authors have done to make it easier for you to understand the article? Any such instances are good candidates for inclusion in your own communications about related ideas.",
    "crumbs": [
      "Target trial framework"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 451: Causal Inference",
    "section": "",
    "text": "Become a producer of actionable knowledge by exploring how to quantify the impact of interventions\n\n\nInstructor: Leslie Myint  Class meeting times: MWF 10:50-11:50am  Class location: THEATR 204  Instructor drop-in hours:\n\nOlin-Rice 232\nMondays and Fridays: 2-3pm\nTuesdays and Thursdays: 3:30-4:30pm"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Check here to see what you should be doing before, during, and after each class day."
  },
  {
    "objectID": "schedule.html#day1",
    "href": "schedule.html#day1",
    "title": "Schedule",
    "section": "Day 1: Welcome! (9/4)",
    "text": "Day 1: Welcome! (9/4)\nBefore class:\n\nGet acquainted with our course by reading the syllabus and touring our course website and Moodle page.\n\nDuring class: Introductions and foundations\nAfter class:\n\n\n\n\n\n\nRequired\n\n\n\nThe following chapters from The Effect lay the foundation for asking good questions. They‚Äôre written in a fun, conversational style and have some nice humor interspersed throughout.\n\nThe Effect Chapter 1: Designing Research (~10 minutes)\n\nVideo alternative: Designing Research (~8 minutes)\n\nThe Effect Chapter 2: Research Questions (~30 minutes)\n\nVideo alternative: Research Questions (~11 minutes)\n\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\nIf you would like to have an additional reference throughout the course that leans more technical and economics-leaning, I recommend starting Causal Inference: The Mixtape by reading Chapter 1: Introduction (~35 minutes).\n\nNote: Scott uses the term endogenous in Section 1.3 without defining it. This is an economics term that essentially parallels the term confounding in statistics. That is, an endogenous variable is (often) one that is a confounder."
  },
  {
    "objectID": "schedule.html#day2",
    "href": "schedule.html#day2",
    "title": "Schedule",
    "section": "Day 2: Causal identification (9/6)",
    "text": "Day 2: Causal identification (9/6)\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\nThe Effect Chapter 5: Identification (~50 minutes)\n\nVideo alternatives:\n\nIdentification: Data Generating Processes (~8 minutes)\nIdentification: Alternative Explanations (~9 minutes)\nIdentification: Alcohol and Mortality (~9 minutes)"
  },
  {
    "objectID": "schedule.html#day3",
    "href": "schedule.html#day3",
    "title": "Schedule",
    "section": "Day 1: Causal graph fundamentals (9/9)",
    "text": "Day 1: Causal graph fundamentals (9/9)\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\nThe Effect Chapter 6: Causal Diagrams (~40 min)\n\nVideo alternatives:\n\nCausal Diagrams: Causality (~9 minutes)\nCausal Diagrams (~12 minutes)\n\n\nThe Effect Chapter 7: Drawing Causal Diagrams (~30 min)\n\nVideo alternatives:\n\nDrawing Causal Diagrams (~13 minutes)\nSimplifying Causal Diagrams (~12 minutes)\n\n\n\nFormulate a research question that relates to an area that you‚Äôre interested in. In class, we will be using the principles in Chapters 6 and 7 to draw a causal diagram that addresses this research question.\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\nMixtape Chapter 3: Directed Acyclic Graphs but skip 3.1.3 Backdoor Criterion (~40 minutes)"
  },
  {
    "objectID": "schedule.html#day4",
    "href": "schedule.html#day4",
    "title": "Schedule",
    "section": "Day 2: Simulating data using causal graphs (9/11)",
    "text": "Day 2: Simulating data using causal graphs (9/11)\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\nVideo: Key structures in causal graphs (~12 min) (slides)\n\nNote 1: In this video, I refer to a concept called ‚Äúexchangeability‚Äù. This is a concept that I included in the last offering of this course. Exchangeability is a causal identification assumption. When the exchangeability assumption is satisfied, we can identify causal effects. When it is not satisfied, I call this ‚Äúa lack of exchangeability‚Äù. In the language we have used, this happens when there are alternate (noncausal) explanations for a relationship between two variables. So in the video, whenever you hear ‚Äúcreates a lack of exchangeability‚Äù, replace that with ‚Äúleads to the presence of alternate (noncausal) explanations for the relationship between two variables‚Äù. When you hear ‚Äúachieve conditional exchangeability‚Äù, replace that with ‚Äúwe are able to address this alternate explanation when analyzing the data‚Äù.\nNote 2: I use the formal probability ideas of marginal and conditional dependence and independence. You can get the essential ideas from this video by replacing terms in the list below. (If you want to learn or review these probability ideas (not required!), watch my Probability Essentials video.)\n\n‚ÄúA and B are marginally [independent/dependent]‚Äù = ‚ÄúA and B are [unrelated/related] in a general population‚Äù\n‚ÄúA and B are conditionally independent‚Äù = ‚ÄúA and B are [unrelated/related] in subgroups (in each group defined by one or more variables)‚Äù\n\n\n2 readings from Andrew Heiss‚Äôs Program Evaluation course:\n\nGenerating random numbers (~35 min)\nThe ultimate guide to generating synthetic data for causal inference (Stop when you get to the subsection ‚ÄúVisualizing one variable‚Äù) (~25 min)\n\n\n\n\nDuring class: Simulating data using causal graphs"
  },
  {
    "objectID": "schedule.html#day5",
    "href": "schedule.html#day5",
    "title": "Schedule",
    "section": "Day 3: Simulating data using causal graphs (9/13)",
    "text": "Day 3: Simulating data using causal graphs (9/13)\n\nContinuation of last class"
  },
  {
    "objectID": "schedule.html#day6",
    "href": "schedule.html#day6",
    "title": "Schedule",
    "section": "Day 1: Identifying causal effects with causal graphs (9/16)",
    "text": "Day 1: Identifying causal effects with causal graphs (9/16)\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\nVideo: Causal and Noncausal Paths (~5 min)\nVideo: D-Separation (~8 min)\nReading: The Effect Chapter 8: Causal Paths and Closing Back Doors (~35 minutes)\n\nVideo alternatives:\n\nCausal Pathways (~9 minutes)\nClosing Causal Pathways, and Collider Variables (~11 minutes)\nTesting Causal Diagrams, and Placebo Tests (~8 minutes)\n\n\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\nMixtape Section 3.1.3: Backdoor criterion (~5 minutes)\n\n\n\n\nDuring class: Identifying causal effects with causal graphs"
  },
  {
    "objectID": "schedule.html#day7",
    "href": "schedule.html#day7",
    "title": "Schedule",
    "section": "Day 2: Identifying causal effects with causal graphs (9/18)",
    "text": "Day 2: Identifying causal effects with causal graphs (9/18)\n\nContinuation of previous class\n\nDuring class: Identifying causal effects with causal graphs and Testing causal graphs"
  },
  {
    "objectID": "schedule.html#day8",
    "href": "schedule.html#day8",
    "title": "Schedule",
    "section": "Day 3: Synthesis day (9/20)",
    "text": "Day 3: Synthesis day (9/20)\n\nPause day to work on Assignment 2.\nPlease create a rough outline of your slides before class.\nWe will have a chance to get feedback on the outline, work on the slides, and then get additional feedback on the slide content."
  },
  {
    "objectID": "schedule.html#day9",
    "href": "schedule.html#day9",
    "title": "Schedule",
    "section": "Day 1: Randomized experiments (9/23)",
    "text": "Day 1: Randomized experiments (9/23)\nBefore class: No required reading or videos for today.\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\nReading: Treatment Allocation and Randomization (~20 minutes) from Penn State‚Äôs online notes for the course Design and Analysis of Clinical Trials\n\n\n\n\nDuring class: Randomized experiments"
  },
  {
    "objectID": "schedule.html#day10",
    "href": "schedule.html#day10",
    "title": "Schedule",
    "section": "Day 2: Target trial framework (9/25)",
    "text": "Day 2: Target trial framework (9/25)\n\n\n\n\n\n\nRequired\n\n\n\n\nReading: Hern√°n, M. A., Sauer, B. C., Hern√°ndez-D√≠az, S., Platt, R., Shrier, I. (2016). Specifying a target trial prevents immortal time bias and other self-inflicted injuries in observational analyses. Journal of Clinical Epidemiology, 79, 70‚Äì75. (~35 minutes)\n\n\n\nDuring class: Target trial framework"
  },
  {
    "objectID": "schedule.html#day11",
    "href": "schedule.html#day11",
    "title": "Schedule",
    "section": "Day 3: Matching (9/27)",
    "text": "Day 3: Matching (9/27)\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\nThe Effect Chapter 14: Matching (~160 minutes)\n\nVideo alternatives:\n\nMatching (~11 minutes)\nFive Questions About Matching (~13 minutes)\nDistance Matching (~9 minutes)\nPropensity Score Matching (~10 minutes)\nCoarsened Exact Matching and Entropy Balancing (~8 minutes)\nWhen Matching Goes Wrong (~14 minutes)\nTreatment Effect Estimation with Matching (~7 minutes)\n\n\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\nMixtape Chapter 5: Matching and Subclassification (~140 minutes)\nJournal article: Matching Methods for Causal Inference: A Review and a Look Forward (~60 minutes)"
  },
  {
    "objectID": "schedule.html#day12",
    "href": "schedule.html#day12",
    "title": "Schedule",
    "section": "Day 1: Matching (9/30)",
    "text": "Day 1: Matching (9/30)\n\nContinuation of previous class"
  },
  {
    "objectID": "schedule.html#day13",
    "href": "schedule.html#day13",
    "title": "Schedule",
    "section": "Day 2: Regression discontinuity (10/2)",
    "text": "Day 2: Regression discontinuity (10/2)\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\nThe Effect Chapter 20: Regression Discontinuity (~130 minutes)\n\nVideo alternatives:\n\nRegression Discontinuity (~10 minutes)\nEstimating Regression Discontinuity (~11 minutes)\nAdjustments to Regression Discontinuity (~8 minutes)\nChecking Regression Discontinuity Assumptions (~11 minutes)\n\n\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\nMixtape Chapter 6: Regression Discontinuity (~170 minutes)"
  },
  {
    "objectID": "schedule.html#day14",
    "href": "schedule.html#day14",
    "title": "Schedule",
    "section": "Day 3: Flex Day (10/4)",
    "text": "Day 3: Flex Day (10/4)\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)"
  },
  {
    "objectID": "schedule.html#day-1-event-studies-interrupted-times-series",
    "href": "schedule.html#day-1-event-studies-interrupted-times-series",
    "title": "Schedule",
    "section": "Day 1: Event studies / interrupted times series",
    "text": "Day 1: Event studies / interrupted times series\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\nThe Effect Chapter 17: Event Studies (~70 minutes)\n\nVideo alternatives:\n\nEvent Studies (~12 minutes)\nInterrupted Time Series (~8 minutes)\nEvent Studies in Finance (~11 minutes)\n\n\n\n\n\nDuring class:"
  },
  {
    "objectID": "schedule.html#day-2-synthetic-control",
    "href": "schedule.html#day-2-synthetic-control",
    "title": "Schedule",
    "section": "Day 2: Synthetic control",
    "text": "Day 2: Synthetic control\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\nThe Effect Section 21.2.1: Synthetic Control (~10 minutes)\n\nVideo alternatives:\n\nOther Standard Research Designs (~5 minutes) (Just the part on the synthetic control method)\n\n\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\nMixtape Chapter 10: Synthetic Control (~70 minutes)\n\n\n\n\nDuring class:"
  },
  {
    "objectID": "schedule.html#day-3-flex-day",
    "href": "schedule.html#day-3-flex-day",
    "title": "Schedule",
    "section": "Day 3: Flex Day",
    "text": "Day 3: Flex Day\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)"
  },
  {
    "objectID": "schedule.html#day-1-fixed-effects-models",
    "href": "schedule.html#day-1-fixed-effects-models",
    "title": "Schedule",
    "section": "Day 1: Fixed effects models",
    "text": "Day 1: Fixed effects models\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\nThe Effect Chapter 16: Fixed Effects (~70 minutes)\n\nVideo alternatives:\n\nFixed Effects (~12 minutes)\nEstimating Fixed Effects (~8 minutes)\nRandom Effects (~6 minutes)\n\n\n\n\n\nDuring class:"
  },
  {
    "objectID": "schedule.html#day-2-difference-in-differences-designs",
    "href": "schedule.html#day-2-difference-in-differences-designs",
    "title": "Schedule",
    "section": "Day 2: Difference-in-differences designs",
    "text": "Day 2: Difference-in-differences designs\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\nThe Effect Chapter 18: Difference-in-Differences (~80 minutes)\n\nVideo alternatives:\n\nDifference in Differences (~11 minutes)\nParallel Trends (~9 minutes)\nEstimating Difference in Differences (~10 minutes)\nSupporting Parallel Trends (~9 minutes)\nDynamic Difference-in-Differences (~10 minutes)\nStaggered Treatment in Difference-in-Differences (~9 minutes)\n\n\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\nMixtape Chapter 9: Difference-in-Differences (~230 minutes)\n\n\n\n\nDuring class:\nüçÅ Fall Break: Thursday, October 17 - Sunday, October 20 üçÅ\nüçÅ No class on Friday, October 18 üçÅ"
  },
  {
    "objectID": "schedule.html#instrumental-variables",
    "href": "schedule.html#instrumental-variables",
    "title": "Schedule",
    "section": "Instrumental variables",
    "text": "Instrumental variables\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\nThe Effect Chapter 19: Instrumental Variables (~85 minutes)\n\nVideo alternatives:\n\nInstrumental Variables (~10 minutes)\nInstrumental Variable Validity (~10 minutes)\nEstimating Instrumental Variables (~12 minutes)\nTesting Instrumental Variables Assumptions (~11 minutes)\n\n\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\nMixtape Chapter 7: Instrumental Variables (~150 minutes)"
  },
  {
    "objectID": "schedule.html#instrumental-variables-1",
    "href": "schedule.html#instrumental-variables-1",
    "title": "Schedule",
    "section": "Instrumental variables",
    "text": "Instrumental variables\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n(~xx minutes)\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)\n\n\n\n\nDuring class:"
  },
  {
    "objectID": "schedule.html#doubly-robust-estimation",
    "href": "schedule.html#doubly-robust-estimation",
    "title": "Schedule",
    "section": "Doubly robust estimation",
    "text": "Doubly robust estimation\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n(~xx minutes)\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)"
  },
  {
    "objectID": "schedule.html#flex-day",
    "href": "schedule.html#flex-day",
    "title": "Schedule",
    "section": "Flex Day",
    "text": "Flex Day\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n(~xx minutes)\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)\n\n\n\n\nDuring class:"
  },
  {
    "objectID": "schedule.html#project-work",
    "href": "schedule.html#project-work",
    "title": "Schedule",
    "section": "Project work",
    "text": "Project work\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n(~xx minutes)\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)"
  },
  {
    "objectID": "schedule.html#causal-discovery",
    "href": "schedule.html#causal-discovery",
    "title": "Schedule",
    "section": "Causal discovery",
    "text": "Causal discovery\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n(~xx minutes)\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)"
  },
  {
    "objectID": "schedule.html#sensitivity-analyses",
    "href": "schedule.html#sensitivity-analyses",
    "title": "Schedule",
    "section": "Sensitivity analyses",
    "text": "Sensitivity analyses\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n(~xx minutes)\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)\n\n\n\n\nDuring class:"
  },
  {
    "objectID": "schedule.html#sensitivity-analyses-1",
    "href": "schedule.html#sensitivity-analyses-1",
    "title": "Schedule",
    "section": "Sensitivity analyses",
    "text": "Sensitivity analyses\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n(~xx minutes)\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)\n\n\n\n\nDuring class:\nü¶É Thanksgiving Break: Wednesday, November 27 - Sunday, December 1 ü¶É"
  },
  {
    "objectID": "schedule.html#day-1-project-work-time",
    "href": "schedule.html#day-1-project-work-time",
    "title": "Schedule",
    "section": "Day 1: Project work time",
    "text": "Day 1: Project work time\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n(~xx minutes)\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)"
  },
  {
    "objectID": "schedule.html#day-2-project-work-time",
    "href": "schedule.html#day-2-project-work-time",
    "title": "Schedule",
    "section": "Day 2: Project work time",
    "text": "Day 2: Project work time\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n(~xx minutes)\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)\n\n\n\n\nDuring class:"
  },
  {
    "objectID": "schedule.html#day-3-project-work-time",
    "href": "schedule.html#day-3-project-work-time",
    "title": "Schedule",
    "section": "Day 3: Project work time",
    "text": "Day 3: Project work time\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n(~xx minutes)\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)\n\n\n\n\nDuring class:"
  },
  {
    "objectID": "schedule.html#day-1-tbd",
    "href": "schedule.html#day-1-tbd",
    "title": "Schedule",
    "section": "Day 1: TBD",
    "text": "Day 1: TBD\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n(~xx minutes)\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)"
  },
  {
    "objectID": "schedule.html#day-2-last-day-of-class",
    "href": "schedule.html#day-2-last-day-of-class",
    "title": "Schedule",
    "section": "Day 2: Last day of class!",
    "text": "Day 2: Last day of class!\nBefore class:\n\n\n\n\n\n\nRequired\n\n\n\n\n(~xx minutes)\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\n\n(~xx)\n\n\n\n\nDuring class:"
  },
  {
    "objectID": "slides/09-rdd.html#big-idea",
    "href": "slides/09-rdd.html#big-idea",
    "title": "Regression Discontinuity Designs",
    "section": "Big idea",
    "text": "Big idea\n\nCutoff on a continuous variable assigns units to treatment vs.¬†control.\n\nCalled the running or forcing variable and often denoted as \\(X\\)\n\nAre units just above the cutoff vs.¬†just below really all that different?\n\nProbably not, and that‚Äôs helpful to us!\nThose just above the cutoff are good guesses for the counterfactual outcome for those just below, and vice versa."
  },
  {
    "objectID": "slides/09-rdd.html#examples",
    "href": "slides/09-rdd.html#examples",
    "title": "Regression Discontinuity Designs",
    "section": "Examples",
    "text": "Examples\n\nElections: Cutoff at 50% determines party in governance within a geographical unit\n\nVariety of social, political, and economic outcomes of interest\nAre districts with 50.1% of votes for Democrats really different from those with 49.9%?\nThe former are definitely governed by Democrats, and the latter are not.\n\nEnvironmental exposures: Thresholds define ‚Äúhigh‚Äù levels of exposure\n\nRadon test when buying a home: if measured radon exceeds 4 pCi/L (picocuries/liter), seller is more likely to pay for a radon mitigation system as part of closing the deal.\nAre homes with 4 pCi/L really different from those with 3.9 pCi/L?\nThe former are more likely to have a radon mitigation system.\n\n\nHilton Boon et al (2021) provide an overview of forcing variables that are commonly used in health studies‚Äîtake (see Table 1)."
  },
  {
    "objectID": "slides/09-rdd.html#sharp-vs.-fuzzy-rdds",
    "href": "slides/09-rdd.html#sharp-vs.-fuzzy-rdds",
    "title": "Regression Discontinuity Designs",
    "section": "Sharp vs.¬†fuzzy RDDs",
    "text": "Sharp vs.¬†fuzzy RDDs\n\nScenario 1: Districts with over 50% of votes for a candidate are wholly governed by that candidate.\nScenario 2: Homes with over 4 pCi/L of radon don‚Äôt always get a radon mitigation system.\nScenario 1 is a sharp RDD because the probability of treatment goes from 0 to 1 at the cutoff.\nScenario 2 is a fuzzy RDD because the probability of treatment changes sharply at the cutoff but not necessarily from 0 to 1.\n\n{fig-alt=‚ÄúDifference betwen sharp and fuzzy regression discontinuity designs. Both panels show the proportion treated as a function of the cutoff.}"
  },
  {
    "objectID": "slides/09-rdd.html#continuity-assumption-and-rdd-plot",
    "href": "slides/09-rdd.html#continuity-assumption-and-rdd-plot",
    "title": "Regression Discontinuity Designs",
    "section": "Continuity assumption and RDD plot",
    "text": "Continuity assumption and RDD plot\n\nNot only does the running variable affect treatment, it also affects the outcome.\nWhat would things look like if everyone received tre"
  },
  {
    "objectID": "slides/09-rdd.html#underlying-causal-graph",
    "href": "slides/09-rdd.html#underlying-causal-graph",
    "title": "Regression Discontinuity Designs",
    "section": "Underlying causal graph",
    "text": "Underlying causal graph"
  },
  {
    "objectID": "slides/09-rdd.html#overview-of-analysis",
    "href": "slides/09-rdd.html#overview-of-analysis",
    "title": "Regression Discontinuity Designs",
    "section": "Overview of analysis",
    "text": "Overview of analysis\nOutline of major steps\n\nCheck integrity of forcing variable\nEvaluate continuity assumption with placebo tests\nRDD modeling"
  },
  {
    "objectID": "slides/09-rdd.html#context-for-the-study",
    "href": "slides/09-rdd.html#context-for-the-study",
    "title": "Regression Discontinuity Designs",
    "section": "Context for the study",
    "text": "Context for the study\nPick either DWI from mixtape or govt transfers from the effect.\nDWI is sharp (pro) Is govt transfers sharp? DWI has full data? gov transfers def does not have full data"
  },
  {
    "objectID": "slides/09-rdd.html#check-forcing-variable-via-context",
    "href": "slides/09-rdd.html#check-forcing-variable-via-context",
    "title": "Regression Discontinuity Designs",
    "section": "Check forcing variable: via context",
    "text": "Check forcing variable: via context"
  },
  {
    "objectID": "slides/09-rdd.html#check-forcing-variable-via-plots",
    "href": "slides/09-rdd.html#check-forcing-variable-via-plots",
    "title": "Regression Discontinuity Designs",
    "section": "Check forcing variable: via plots",
    "text": "Check forcing variable: via plots\nnuances of making histogram with the right binwidth - good first guess at binwidth -"
  },
  {
    "objectID": "slides/09-rdd.html#check-forcing-variable-tests",
    "href": "slides/09-rdd.html#check-forcing-variable-tests",
    "title": "Regression Discontinuity Designs",
    "section": "check forcing variable: tests",
    "text": "check forcing variable: tests"
  },
  {
    "objectID": "slides/09-rdd.html#rdd-modeling-overview",
    "href": "slides/09-rdd.html#rdd-modeling-overview",
    "title": "Regression Discontinuity Designs",
    "section": "RDD modeling overview",
    "text": "RDD modeling overview\n\nLook at y vs.¬†forcing plot to get a sense for global vs.¬†local"
  },
  {
    "objectID": "slides/09-rdd.html#global-model",
    "href": "slides/09-rdd.html#global-model",
    "title": "Regression Discontinuity Designs",
    "section": "Global model",
    "text": "Global model\nimportance of correct functional form"
  },
  {
    "objectID": "slides/09-rdd.html#local-model",
    "href": "slides/09-rdd.html#local-model",
    "title": "Regression Discontinuity Designs",
    "section": "Local model",
    "text": "Local model\nneed to select bandwidth - different methods for choosing bandwidth"
  },
  {
    "objectID": "slides/09-rdd.html#placebo-tests",
    "href": "slides/09-rdd.html#placebo-tests",
    "title": "Regression Discontinuity Designs",
    "section": "Placebo tests",
    "text": "Placebo tests\nsame RDD model but replace y with pre-treatment covariates Use same bw as for main RDD model?"
  }
]